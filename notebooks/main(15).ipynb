{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMn2Zz06M2jh"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLBwNxwn3oog"
      },
      "source": [
        "This notebook presents several classifiers aiming to predict startups success (aquired or failed, no IPO data in the imput dataset) based on the avaliable data.\n",
        " For the input data analysis, please view EDA notebood in the same repository.\n",
        " The dataset can be found here: https://www.kaggle.com/datasets/manishkc06/startup-success-prediction/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivrkwzqf4JDX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-CMo8UO3pro"
      },
      "source": [
        " # Take code from git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mj02UewM8va",
        "outputId": "fe4aee25-1fb8-49ba-f20a-b1b08cfffbed"
      },
      "outputs": [],
      "source": [
        "# !rm -r Applied_DS_Project # pay attention!\n",
        "# !git clone https://github.com/MayaVB/Applied_DS_Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwFPs4tJQlDU",
        "outputId": "37d1f448-4c62-4227-c2f0-c8e80fb84bf6"
      },
      "outputs": [],
      "source": [
        "# !ls Applied_DS_Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzB6GBanNbxC",
        "outputId": "ae2388c1-9b64-46f2-94fa-8a380fb12d04"
      },
      "outputs": [],
      "source": [
        "# !ls Applied_DS_Project/src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OUrJNfVQp65"
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "AkPohH49QqHd",
        "outputId": "5f1f015e-87a3-4cd2-96bc-2a8553a24a81"
      },
      "outputs": [],
      "source": [
        "# !pip install -r Applied_DS_Project/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SDhtedT4RV75"
      },
      "outputs": [],
      "source": [
        "# consider for future features\n",
        "# %pip install yfinance\n",
        "# %pip install tweepy\n",
        "# %pip install wbdata pandas\n",
        "# %pip install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or-0hjlUM4An"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgC6z8LXM2jk",
        "outputId": "b703eb2b-3ccd-4e9f-b6d4-67d85083222b"
      },
      "outputs": [],
      "source": [
        "# set working directory:\n",
        "# %cd Applied_DS_Project/src\n",
        "\n",
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.stats import mode\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from eval import plot_feature_importances, plot_auc_roc_curve, perform_cross_validation\n",
        "from getdata import add_nasdaq_annual_changes, add_economic_indicators\n",
        "from models import train_xgb_model, train_rf_model, train_svm_model, train_decision_tree_model\n",
        "from models import train_rfv2_model, evaluate_model, predict_model\n",
        "from printstatistics import print_correlations_Spearman_and_Pearson\n",
        "from preprocess import preprocess_data, preprocess_data_classifier\n",
        "from utils import set_seed, load_data\n",
        "from regression_models import train_and_evaluate_r\n",
        "from eval import get_ratio, cross_validation_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "112DTMAeM2jm"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data and Economics indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = load_data('../data/startup_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poBveSn0M2jn",
        "outputId": "81464be3-e685-4b7a-9011-ccbfcdc36094"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "df = load_data('../data/startup_data.csv')\n",
        "\n",
        "# Add economic indicators\n",
        "df = add_nasdaq_annual_changes(df)\n",
        "indicator_code = 'NY.GDP.MKTP.KD.ZG'\n",
        "df = add_economic_indicators(df, indicator_code)\n",
        "indicator_code = 'SL.UEM.TOTL.ZS'\n",
        "df = add_economic_indicators(df, indicator_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocess Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mayavb/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the data\n",
        "X, y = preprocess_data_classifier(df, useKNNImputer=True)\n",
        "\n",
        "random_state = 42\n",
        "set_seed(random_state)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bv9xiWUM2jn"
      },
      "source": [
        "# Train predict and evaluate classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5kyQq4X1X-r"
      },
      "source": [
        "## XG Boost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v2etibIIFmN"
      },
      "source": [
        "### cross-validation with 5-fold stratified sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kQyAVn1rM2jn",
        "outputId": "7e5eef41-68e8-4efa-d69b-b25a35761b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   3.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   2.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   4.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   6.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   6.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   2.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   3.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   4.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   3.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   3.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   6.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   3.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   2.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   3.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   3.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   4.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   3.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   2.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   5.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   5.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   4.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   3.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   3.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   4.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.9; total time=   3.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   5.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=1.0; total time=   4.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   3.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   3.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   3.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   2.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   3.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   2.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   5.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   4.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   2.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   3.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   2.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.8; total time=   2.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.9; total time=   9.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.8; total time=   9.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   3.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   2.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   3.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.9; total time=   4.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   4.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   3.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=200, subsample=1.0; total time=   5.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   4.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   3.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   3.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   4.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.9; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.9; total time=   6.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=100, subsample=0.8; total time=   4.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.8; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   3.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=0.9; total time=   3.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   3.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   3.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=200, subsample=1.0; total time=   3.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=300, subsample=1.0; total time=  10.0s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   4.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   2.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   2.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   3.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   4.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   2.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.8; total time=   4.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=0.9; total time=   4.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   4.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=10, n_estimators=300, subsample=1.0; total time=   5.9s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=200, subsample=0.8; total time=   2.9s\n"
          ]
        }
      ],
      "source": [
        "xgb_clf = train_xgb_model(X_train, y_train)\n",
        "xgb_pred, xgb_prob = predict_model(xgb_clf, X_test)\n",
        "metrics['XGBoost'] = evaluate_model(y_test, xgb_pred, xgb_prob, threshold=0.5)\n",
        "\n",
        "cv_results_xgb = perform_cross_validation(xgb_clf, X_train, y_train, n_splits=5, random_state=random_state)\n",
        "metrics['XGBoost']['Kappa'] = round(cv_results_xgb['test_kappa'].mean(), 2)\n",
        "\n",
        "\n",
        "# plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "# plot_auc_roc_curve(y_test, xgb_prob, model_name='XG-Boost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH3jOszA1qjE"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NjkK8KJuM2jn",
        "outputId": "739fb521-c416-4522-abd8-c7e4a35c2f96"
      },
      "outputs": [],
      "source": [
        "rf_clf = train_rf_model(X_train, y_train)\n",
        "rf_pred, rf_prob = predict_model(rf_clf, X_test)\n",
        "metrics['RandomForest'] = evaluate_model(y_test, rf_pred, rf_prob)\n",
        "\n",
        "cv_results_rf = perform_cross_validation(rf_clf, X_train, y_train, n_splits=5, random_state=random_state)\n",
        "metrics['RandomForest']['Kappa'] = round(cv_results_rf['test_kappa'].mean(), 2)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# plot_feature_importances(rf_clf, feature_names=X.columns, num_of_features=10)\n",
        "# plot_auc_roc_curve(y_test, rf_prob, model_name='randomForest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inl8K6oUF8KO"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iM3W5wk6M2jo",
        "outputId": "bb0ced8c-2a61-4ec2-b485-461b00b0b7c4"
      },
      "outputs": [],
      "source": [
        "svm_clf = train_svm_model(X_train, y_train)\n",
        "svm_pred, svm_prob = predict_model(svm_clf, X_test)\n",
        "metrics['SVM'] = evaluate_model(y_test, svm_pred, svm_prob)\n",
        "\n",
        "cv_results_SVM = perform_cross_validation(svm_clf, X_train, y_train, n_splits=5, random_state=random_state)\n",
        "metrics['SVM']['Kappa'] = round(cv_results_SVM['test_kappa'].mean(), 2)\n",
        "\n",
        "# plot_auc_roc_curve(y_test, svm_prob, model_name='SVM')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DecisionTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_clf = train_decision_tree_model(X_train, y_train)\n",
        "dt_pred, dt_prob = predict_model(dt_clf, X_test)\n",
        "metrics['DecisionTree'] = evaluate_model(y_test, dt_pred, dt_prob)\n",
        "\n",
        "cv_results_dt = perform_cross_validation(dt_clf, X_train, y_train, n_splits=5, random_state=random_state)\n",
        "metrics['DecisionTree']['Kappa'] = round(cv_results_dt['test_kappa'].mean(), 2)\n",
        "\n",
        "# plot_feature_importances(dt_clf, feature_names=X.columns, num_of_features=10)\n",
        "# plot_auc_roc_curve(y_test, dt_prob, model_name='DecisionTree')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip7huHQEOMJC"
      },
      "source": [
        "# Ensemble classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL5_z0tRSiCC"
      },
      "source": [
        "## Ensemble all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-RoSmmmwPrUR",
        "outputId": "a76cde38-8c22-4d1a-a43c-349348cc9600"
      },
      "outputs": [],
      "source": [
        "# Stack the predictions into a matrix\n",
        "predictions = np.vstack((xgb_pred, rf_pred, svm_pred, dt_pred)).T\n",
        "\n",
        "# Majority voting\n",
        "ensemble_pred, _ = mode(predictions, axis=1)\n",
        "ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "# Combine probabilities (e.g., by averaging them)\n",
        "ensemble_prob = (xgb_prob + rf_prob + svm_prob + dt_prob) / 4\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "evaluate_model(y_test, ensemble_pred, ensemble_prob, threshold=0.5)\n",
        "\n",
        "# Plot feature importances and AUC-ROC curves\n",
        "# plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "# plot_auc_roc_curve(y_test, ensemble_prob, model_name='Ensemble')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsE1hH08Snco"
      },
      "source": [
        "## Ensemble selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "61PT5w9xR_Qy",
        "outputId": "a3979def-0122-4b92-e914-947e383ae196"
      },
      "outputs": [],
      "source": [
        "# Stack the predictions into a matrix\n",
        "predictions = np.vstack((xgb_pred, rf_pred)).T\n",
        "\n",
        "# Majority voting\n",
        "ensemble_pred, _ = mode(predictions, axis=1)\n",
        "ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "# Combine probabilities (e.g., by averaging them)\n",
        "ensemble_prob = (xgb_prob + rf_prob) / 2\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "metrics['Ensemble'] = evaluate_model(y_test, ensemble_pred, ensemble_prob, threshold=0.5)\n",
        "\n",
        "# Plot feature importances and AUC-ROC curves\n",
        "# plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "# plot_auc_roc_curve(y_test, ensemble_prob, model_name='Ensemble')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLJc9ozSQLBo"
      },
      "source": [
        "# Analyse classifier results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plot all models results graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the models\n",
        "models = ['XGBoost', 'RandomForest', 'SVM', 'DecisionTree', 'Ensemble']\n",
        "colors = sns.color_palette('coolwarm', n_colors=len(models))\n",
        "\n",
        "# Create a dictionary to map the model names to the pastel colors\n",
        "color_mapping = dict(zip(models, colors))\n",
        "\n",
        "# Convert metrics to DataFrame for plotting\n",
        "metrics_df = pd.DataFrame(metrics).T\n",
        "metrics_df = metrics_df.reset_index().melt(id_vars='index', var_name='Metric', value_name='Score')\n",
        "metrics_df.columns = ['Model', 'Metric', 'Score']\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Use seaborn to create the bar plot with the pastel colors\n",
        "ax = sns.barplot(\n",
        "    x='Metric', \n",
        "    y='Score', \n",
        "    hue='Model', \n",
        "    data=metrics_df, \n",
        "    palette=color_mapping\n",
        ")\n",
        "\n",
        "# Add the numbers on top of the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.2f}', \n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "                ha='center', va='center', \n",
        "                xytext=(0, 9), \n",
        "                textcoords='offset points')\n",
        "\n",
        "plt.title('Model Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metric')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKU5VPw0ArLI"
      },
      "source": [
        "## Combine with the original features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "XPPYIxrp1OjP",
        "outputId": "ecdfd600-0d38-47ad-d30e-d6c0ed6b698b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame with all features, y_test, and predictions\n",
        "result_df = pd.DataFrame(X_test, columns=X.columns)\n",
        "result_df['Actual'] = y_test.values\n",
        "'''\n",
        "result_df['Predicted_xgb'] = xgb_pred\n",
        "result_df['Probability_xgb'] = xgb_prob\n",
        "result_df['Predicted_rfv2'] = rfv2_pred\n",
        "result_df['Probability_rfv2'] = rfv2_prob\n",
        "result_df['Predicted_rf'] = rf_pred\n",
        "result_df['Probability_rf'] = rf_prob\n",
        "result_df['Predicted_svm'] = svm_pred\n",
        "result_df['Probability_svm'] = svm_prob\n",
        "'''\n",
        "result_df['Predicted_ensemble'] = ensemble_pred\n",
        "result_df['Probability_ensemble'] = ensemble_prob\n",
        "\n",
        "# Display the DataFrame\n",
        "result_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otOXyBK1OgXD"
      },
      "source": [
        "## try - drafts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFfwTOcqPpa-"
      },
      "outputs": [],
      "source": [
        "df1 = load_data('../data/startup_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUGTRQekICxZ",
        "outputId": "d3bd8816-5121-4f5f-f16a-af0f05bf4e4b"
      },
      "outputs": [],
      "source": [
        "result_df_ok = result_df[result_df['Predicted_ensemble'] == result_df['Actual']]\n",
        "result_df_fail = result_df[result_df['Predicted_ensemble'] != result_df['Actual']]\n",
        "\n",
        "print(result_df_ok['category_code_biotech'].value_counts() / len(result_df_ok))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWVbPO1_ICxZ",
        "outputId": "345a88a4-80a7-4f39-8c6b-8f79a3b5d9d3"
      },
      "outputs": [],
      "source": [
        "# Correlation analysis for incorrect predictions, to see which features correlate with the errors, focusing on predicted values\n",
        "incorrect_corr = (result_df_fail.corr())\n",
        "print(\"Correlation in Incorrect Predictions with Predicted Values:\\n\", incorrect_corr['Predicted_ensemble'].sort_values(ascending=False).head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nZGsoQwICxZ"
      },
      "outputs": [],
      "source": [
        "# Add a new column 'predicted_correctly' to the DataFrame\n",
        "result_df['predicted_correctly'] = (result_df['Predicted_ensemble'] == result_df['Actual']).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hZOX3pG7ICxa",
        "outputId": "5add361f-43a9-4cdb-db10-a7881bdc8aee"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the total predictions for each category and the correct prediction rate\n",
        "category_analysis = {}\n",
        "\n",
        "for column in result_df.columns:\n",
        "    if column.startswith('category_code_'):\n",
        "        total = result_df[column].sum()  # total instances of this category\n",
        "        correct = result_df[result_df['predicted_correctly'] == 1][column].sum()\n",
        "        accuracy = correct / total if total > 0 else 0\n",
        "        incorrect = total - correct\n",
        "        category_name = column.replace('category_code_', '')\n",
        "        category_analysis[category_name] = {'Total': total, 'Correct': correct, 'Incorrect': incorrect, 'Accuracy': accuracy}\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "category_df = pd.DataFrame.from_dict(category_analysis, orient='index')\n",
        "category_df = category_df.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count of 0\n",
        "category_df = category_df[category_df['Total'] > 0]\n",
        "\n",
        "print(category_df)\n",
        "\n",
        "# Plot the accuracy with quantitative information\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Accuracy', color=color)\n",
        "ax1.bar(category_df.index, category_df['Accuracy'], color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Create a second y-axis for the total counts\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(category_df.index, category_df['Total'], color=color, marker='o')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Category Analysis: Accuracy vs. Total Predictions')\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp1fxv7UkTWM"
      },
      "source": [
        "## The classifier Performance on different categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "YEwjIwwSICxa",
        "outputId": "a19406d9-6665-4ce0-87c8-3ca02239031c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the total predictions for each category and the correct/incorrect prediction counts\n",
        "category_analysis = {}\n",
        "\n",
        "for column in result_df.columns:\n",
        "    if column.startswith('category_code_'):\n",
        "        total = result_df[column].sum()  # total instances of this category\n",
        "        correct = result_df[result_df['predicted_correctly'] == 1][column].sum()\n",
        "        incorrect = total - correct\n",
        "        category_name = column.replace('category_code_', '')\n",
        "        category_analysis[category_name] = {'Total': total, 'Correct': correct, 'Incorrect': incorrect}\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "category_df = pd.DataFrame.from_dict(category_analysis, orient='index')\n",
        "category_df = category_df.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count <5\n",
        "category_df = category_df[category_df['Total'] > 5]\n",
        "\n",
        "print(category_df)\n",
        "\n",
        "# Plot the correct and incorrect predictions side by side with a secondary y-axis for total predictions\n",
        "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(category_df.index))\n",
        "\n",
        "# Bars for correct predictions\n",
        "bars1 = ax1.bar(index, category_df['Correct'], bar_width, label='Correct Predictions', color='tab:green')\n",
        "\n",
        "# Bars for incorrect predictions\n",
        "bars2 = ax1.bar(index + bar_width, category_df['Incorrect'], bar_width, label='Incorrect Predictions', color='tab:red')\n",
        "\n",
        "# Primary y-axis\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Correct vs. Incorrect Predictions by Category')\n",
        "ax1.set_xticks(index + bar_width / 2)\n",
        "ax1.set_xticklabels(category_df.index, rotation=45, ha='right')\n",
        "ax1.legend(loc='upper left')\n",
        "\n",
        "# Secondary y-axis for total predictions\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(index + bar_width / 2, category_df['Total'], color=color, marker='o', linestyle='--')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_CbDPr2kh6B"
      },
      "source": [
        "### same for 5-fold results aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9shPG8a0ICxa",
        "outputId": "d04497fc-c367-41bb-b351-c2c808ff8491"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Assuming your result_df has the necessary columns to be used as features\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "\n",
        "category_analysis_cv = []\n",
        "\n",
        "for train_index, test_index in kf.split(result_df):\n",
        "    train_df, test_df = result_df.iloc[train_index], result_df.iloc[test_index]\n",
        "\n",
        "    # Ensure only the original feature columns are used\n",
        "    feature_columns = X.columns  # Assuming `X` contains the original feature columns\n",
        "\n",
        "    X_train, y_train = train_df[feature_columns], train_df['Actual']\n",
        "    X_test, y_test = test_df[feature_columns], test_df['Actual']\n",
        "\n",
        "    # Replace this with your actual model fitting and predicting code\n",
        "    xgb_pred, xgb_prob = predict_model(xgb_clf, X_test)\n",
        "    rfv2_pred, rfv2_prob = predict_model(rfv2_clf, X_test)\n",
        "    svm_pred, svm_prob = predict_model(svm_clf, X_test)\n",
        "\n",
        "    # Stack the predictions into a matrix\n",
        "    predictions = np.vstack((xgb_pred, rfv2_pred, svm_pred)).T\n",
        "\n",
        "    # Majority voting\n",
        "    ensemble_pred, _ = mode(predictions, axis=1)\n",
        "    ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "    # Store the predicted and actual values in test_df\n",
        "    test_df['Predicted'] = ensemble_pred\n",
        "\n",
        "    # Now calculate the statistics for this fold\n",
        "    for column in result_df.columns:\n",
        "        if column.startswith('category_code_'):\n",
        "            total = test_df[column].sum()  # total instances of this category in the fold\n",
        "            correct = test_df[(test_df['Predicted'] == test_df['Actual'])][column].sum()\n",
        "            incorrect = total - correct\n",
        "            accuracy = correct / total if total > 0 else 0\n",
        "            category_name = column.replace('category_code_', '')\n",
        "            category_analysis_cv.append({'Category': category_name, 'Total': total, 'Correct': correct, 'Incorrect': incorrect, 'Accuracy': accuracy})\n",
        "\n",
        "# Aggregate results across folds\n",
        "category_df_cv = pd.DataFrame(category_analysis_cv)\n",
        "category_df_cv = category_df_cv.groupby('Category').sum()\n",
        "category_df_cv['Accuracy'] = category_df_cv['Correct'] / category_df_cv['Total']\n",
        "\n",
        "# Sort by the most common categories\n",
        "category_df_cv = category_df_cv.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count of <5\n",
        "category_df_cv = category_df_cv[category_df_cv['Total'] > 5]\n",
        "\n",
        "# Set the width for the bars\n",
        "bar_width = 0.35\n",
        "\n",
        "# Plotting Correct vs Incorrect predictions side by side\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Correct & Incorrect Predictions', color=color)\n",
        "\n",
        "# Set the positions for the bars\n",
        "index = np.arange(len(category_df_cv))\n",
        "\n",
        "# Plot the bars side by side\n",
        "ax1.bar(index - bar_width/2, category_df_cv['Correct'], bar_width, color='tab:green', label='Correct')\n",
        "ax1.bar(index + bar_width/2, category_df_cv['Incorrect'], bar_width, color='tab:red', label='Incorrect')\n",
        "\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.set_xticks(index)\n",
        "ax1.set_xticklabels(category_df_cv.index, rotation=45, ha='right')\n",
        "\n",
        "# Create a second y-axis for the total counts\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:purple'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(index, category_df_cv['Total'], color=color, marker='o', label='Total Predictions')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Category Analysis: Accuracy vs. Total Predictions (5-Fold CV)')\n",
        "fig.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Kk93Y9avICxb",
        "outputId": "5d5cc338-8ebb-4993-9e41-52fcb5422634"
      },
      "outputs": [],
      "source": [
        "# Extract GDP and UEM columns\n",
        "gdp_columns = [col for col in result_df.columns if 'GDP_growth_at_year' in col]\n",
        "uem_columns = [col for col in result_df.columns if 'UEM_growth_at_year' in col]\n",
        "\n",
        "# Calculate mean prediction correctness for each year\n",
        "gdp_accuracy = result_df.groupby('predicted_correctly')[gdp_columns].mean().T\n",
        "uem_accuracy = result_df.groupby('predicted_correctly')[uem_columns].mean().T\n",
        "\n",
        "# Assign a vector of 0-10 to the 'Year' column\n",
        "gdp_accuracy['Year'] = list(range(11))\n",
        "uem_accuracy['Year'] = list(range(11))\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# GDP Growth plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(gdp_accuracy['Year'], gdp_accuracy[1], label='Correctly Predicted', marker='o')\n",
        "plt.plot(gdp_accuracy['Year'], gdp_accuracy[0], label='Incorrectly Predicted', marker='o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average GDP Growth')\n",
        "plt.title('Model Performance Based on GDP Growth')\n",
        "plt.legend()\n",
        "\n",
        "# UEM Growth plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(uem_accuracy['Year'], uem_accuracy[1], label='Correctly Predicted', marker='o')\n",
        "plt.plot(uem_accuracy['Year'], uem_accuracy[0], label='Incorrectly Predicted', marker='o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average UEM Growth')\n",
        "plt.title('Model Performance Based on UEM Growth')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "WKG53LChNzDt",
        "outputId": "6a5b2232-1bcc-4e51-86a9-68f09710d872"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# plt.figure(figsize=(14, 5))\n",
        "\n",
        "# # Plot distribution for relationships on the left\n",
        "# plt.subplot(1, 2, 1)\n",
        "# sns.kdeplot(correct_original_df['relationships'], shade=True, label='Correct', color='g')\n",
        "# sns.kdeplot(incorrect_original_df['relationships'], shade=True, label='Incorrect', color='r')\n",
        "# plt.title('Distribution of \"relationships\"')\n",
        "# plt.legend()\n",
        "\n",
        "# # Plot distribution for founded_at_year on the right\n",
        "# plt.subplot(1, 2, 2)\n",
        "# sns.kdeplot(correct_original_df['founded_at_year'], shade=True, label='Correct', color='g')\n",
        "# sns.kdeplot(incorrect_original_df['founded_at_year'], shade=True, label='Incorrect', color='r')\n",
        "# plt.title('Distribution of \"founded_at_year\"')\n",
        "# plt.legend()\n",
        "\n",
        "# # Add a big title to the entire figure\n",
        "# plt.suptitle('High effect Feature Distributions for Correct and Incorrect Predictions', fontsize=16, y=1.05)\n",
        "\n",
        "# # Adjust layout for better spacing\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jiwwHegfPrQw",
        "outputId": "810184a2-da8c-47ae-ce66-1b4889dce601"
      },
      "outputs": [],
      "source": [
        "df1.category_code.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Mf7RrVOyvs",
        "outputId": "8535dcd0-5242-4aee-88b5-a0aa93d6405c"
      },
      "outputs": [],
      "source": [
        "result_df_fail['category_code_biotech'] = result_df_fail.category_code_biotech.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['category_code_biotech'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['category_code_biotech'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLdIA7LzN1b2",
        "outputId": "0e9f14c0-61ca-436e-d0de-8115710f4f65"
      },
      "outputs": [],
      "source": [
        "result_df_fail['category_code_software'] = result_df_fail.category_code_software.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['category_code_software'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['category_code_software'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "eYqLPlyiNNie",
        "outputId": "794b9889-d778-4a55-c8ca-725d7f190f40"
      },
      "outputs": [],
      "source": [
        "result_df_fail['category_code_other'] = result_df_fail.category_code_other.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['is_othercategory'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['category_code_other'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "OpJzXL3ULSHy",
        "outputId": "7dd1599d-63e7-4908-d8ce-1a2b8e3ed4cb"
      },
      "outputs": [],
      "source": [
        "result_df.category_code_other.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnJUoeV-j9D-"
      },
      "source": [
        "# Regressors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIxabMgXLjnJ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate',\n",
        "'category_code', 'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising',\n",
        "'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting', 'is_othercategory',\n",
        "'has_roundB', 'has_roundC', 'has_roundD', 'has_VC', 'has_angel', 'has_roundA',\n",
        "'''\n",
        "'''\n",
        "'closed_at', 'age_first_funding_year', 'age_last_funding_year',\n",
        "'age_first_milestone_year', 'age_last_milestone_year', 'funding_rounds', 'funding_total_usd',\n",
        "'milestones', 'avg_participants',\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl7LR1GiTW01"
      },
      "source": [
        "## predict age_first_funding_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XUTO3jo3Tcid",
        "outputId": "b8664825-5b40-4979-9413-fc1ddab0d7e9"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['age_first_funding_year']\n",
        "df1 = df.drop('age_first_funding_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_first_funding_year', tolerance = 0.4)\n",
        "\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Custom Accuracy within {1} year: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt1vWATvUHkd"
      },
      "source": [
        "## age_last_funding_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b--3jEsgYMir",
        "outputId": "c8948cce-f3fe-4a5d-e444-7885cf7a24dd"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['age_last_funding_year']\n",
        "df1 = df.drop('age_last_funding_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_last_funding_year', tolerance = 0.3)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} year: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q51yGtqzYyPO"
      },
      "source": [
        "## funding_rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MsgWojm6YyXN",
        "outputId": "f9fece6a-4311-4a13-d0d3-8b6951ccd685"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "df1 = df.copy()\n",
        "\n",
        "# Drop rows where 'age_first_milestone_year' is NaN\n",
        "df1.dropna(subset=['age_first_milestone_year'], inplace=True)\n",
        "print(len(df1))\n",
        "y = df1['age_first_milestone_year']\n",
        "df1 = df1.drop('age_first_milestone_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_first_milestone_year', tolerance = 0.3)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} round: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlNgby_-Y6Ae"
      },
      "source": [
        "## funding_total_usd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VKOAlDalY6Jw",
        "outputId": "d43ffb00-757d-40fb-f1fe-d2e0af8de145"
      },
      "outputs": [],
      "source": [
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df, useKNNImputer=True)\n",
        "y = df['funding_total_usd'] # Create target\n",
        "X = X.drop('funding_total_usd', axis=1)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'funding_total_usd', tolerance = 0.4)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} mln usd: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IlMty2qZTVX"
      },
      "source": [
        "## milestones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zy-Nd-ZsZVKS",
        "outputId": "a431c925-ca76-4110-88cc-3b0a6f9246de"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['milestones']\n",
        "df1 = df.copy()\n",
        "df1 = df1.drop('milestones', axis=1)\n",
        "\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'milestones')\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} mln usd: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LaFZz1W0UGTm",
        "outputId": "93a4987b-a41c-4326-d823-a2bf4680aff4"
      },
      "outputs": [],
      "source": [
        "'age_first_funding_year', 'age_last_funding_year',\n",
        "'age_first_milestone_year', 'age_last_milestone_year', 'funding_rounds', 'funding_total_usd',\n",
        "'milestones'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
