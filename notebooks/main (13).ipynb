{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMn2Zz06M2jh"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLBwNxwn3oog"
      },
      "source": [
        "This notebook presents several classifiers aiming to predict startups success (aquired or failed, no IPO data in the imput dataset) based on the avaliable data.\n",
        " For the input data analysis, please view EDA notebood in the same repository.\n",
        " The dataset can be found here: https://www.kaggle.com/datasets/manishkc06/startup-success-prediction/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivrkwzqf4JDX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-CMo8UO3pro"
      },
      "source": [
        " # Take code from git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mj02UewM8va",
        "outputId": "fe4aee25-1fb8-49ba-f20a-b1b08cfffbed"
      },
      "outputs": [],
      "source": [
        "# !rm -r Applied_DS_Project # pay attention!\n",
        "# !git clone https://github.com/MayaVB/Applied_DS_Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwFPs4tJQlDU",
        "outputId": "37d1f448-4c62-4227-c2f0-c8e80fb84bf6"
      },
      "outputs": [],
      "source": [
        "# !ls Applied_DS_Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzB6GBanNbxC",
        "outputId": "ae2388c1-9b64-46f2-94fa-8a380fb12d04"
      },
      "outputs": [],
      "source": [
        "# !ls Applied_DS_Project/src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OUrJNfVQp65"
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "AkPohH49QqHd",
        "outputId": "5f1f015e-87a3-4cd2-96bc-2a8553a24a81"
      },
      "outputs": [],
      "source": [
        "# !pip install -r Applied_DS_Project/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDhtedT4RV75"
      },
      "outputs": [],
      "source": [
        "# consider for future features\n",
        "# %pip install yfinance\n",
        "# %pip install tweepy\n",
        "# %pip install wbdata pandas\n",
        "# %pip install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or-0hjlUM4An"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgC6z8LXM2jk",
        "outputId": "b703eb2b-3ccd-4e9f-b6d4-67d85083222b"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'load_data' from 'preprocess' (/home/mayavb/Documents/PythonProjects/Applied_DS_Project/notebooks/../src/preprocess.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_feature_importances, plot_auc_roc_curve, perform_cross_validation\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgetdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_nasdaq_annual_changes, add_economic_indicators\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_xgb_model, train_rf_model, train_svm_model\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_rfv2_model, evaluate_model, predict_model\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprintstatistics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_correlations_Spearman_and_Pearson\n",
            "File \u001b[0;32m~/Documents/PythonProjects/Applied_DS_Project/notebooks/../src/models.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_ConfusionMatrix_test, get_precision_and_recall\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgetdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_nasdaq_annual_changes, add_economic_indicators\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_data, load_data\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_rfv2_model\u001b[39m(X_train, y_train):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Define hyperparameters for tuning\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m250\u001b[39m],\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m45\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m     20\u001b[0m     }\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_data' from 'preprocess' (/home/mayavb/Documents/PythonProjects/Applied_DS_Project/notebooks/../src/preprocess.py)"
          ]
        }
      ],
      "source": [
        "# set working directory:\n",
        "# %cd Applied_DS_Project/src\n",
        "\n",
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.stats import mode\n",
        "\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from eval import plot_feature_importances, plot_auc_roc_curve, perform_cross_validation\n",
        "from getdata import add_nasdaq_annual_changes, add_economic_indicators\n",
        "from models import train_xgb_model, train_rf_model, train_svm_model\n",
        "from models import train_rfv2_model, evaluate_model, predict_model\n",
        "from printstatistics import print_correlations_Spearman_and_Pearson\n",
        "from preprocess import preprocess_data, preprocess_data_classifier\n",
        "from utils import set_seed, load_data\n",
        "from regression_models import train_and_evaluate_r\n",
        "from eval import get_ratio, cross_validation_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Poh3QKlmM2jm"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuSt9hjnM2jm"
      },
      "outputs": [],
      "source": [
        "df = load_data('../data/startup_data.csv')\n",
        "\n",
        "# Convert the date column to datetime\n",
        "df['first_funding_at'] = pd.to_datetime(df['first_funding_at'])\n",
        "\n",
        "# Extract year, month, and day into separate columns\n",
        "df['first_funding_at_year'] = df['first_funding_at'].dt.year\n",
        "df['first_funding_at_month'] = df['first_funding_at'].dt.month\n",
        "df['first_funding_at_day'] = df['first_funding_at'].dt.day\n",
        "\n",
        "# Convert the date column to datetime\n",
        "df['last_funding_at'] = pd.to_datetime(df['last_funding_at'])\n",
        "\n",
        "# Extract year, month, and day into separate columns\n",
        "df['first_funding_at_year'] = df['last_funding_at'].dt.year\n",
        "df['first_funding_at_month'] = df['last_funding_at'].dt.month\n",
        "df['first_funding_at_day'] = df['last_funding_at'].dt.day\n",
        "\n",
        "\n",
        "df = df.drop(columns=['first_funding_at', 'last_funding_at', 'state_code.1'])\n",
        "#in this dataset state_code is safe to drop as the vast majority of the starttups in this dataset are in locations with high VC activity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvPyeIhFM2jm"
      },
      "outputs": [],
      "source": [
        "# # Create label\n",
        "# df['status_code'] = df['status'].map({'acquired': 1, 'closed': 0})\n",
        "\n",
        "# print_correlations_Spearman_and_Pearson(df['relationships'], df['status_code'])\n",
        "# print_correlations_Spearman_and_Pearson(df['avg_participants'], df['status_code'])\n",
        "# print_correlations_Spearman_and_Pearson(df['has_roundC'], df['status_code'])\n",
        "# print_correlations_Spearman_and_Pearson(df['has_roundD'], df['status_code'])\n",
        "\n",
        "# print_correlations_Spearman_and_Pearson(df['relationships'], df['status_code'])\n",
        "# print_correlations_Spearman_and_Pearson(df['avg_participants'], df['status_code'])\n",
        "# print_correlations_Spearman_and_Pearson(df['has_roundC'], df['status_code'])\n",
        "# print_correlations_Spearman_and_Pearson(df['has_roundD'], df['status_code'])\n",
        "\n",
        "# df.drop(columns=['status_code'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz8iiDO9wcXT"
      },
      "source": [
        "# Visualize geograpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNO18KgCzPWt"
      },
      "source": [
        "See more visualizations in the EDA notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "TTihFXJEweVf",
        "outputId": "cc99c9f4-d321-42b8-a1ba-58d12e9f91da"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "\n",
        "latitude_initial = 39.8283\n",
        "longitude_initial = -50.0000\n",
        "\n",
        "map = folium.Map(location = [latitude_initial, longitude_initial], zoom_start = 3, tiles = 'cartodbpositron')\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    folium.Marker([row['latitude'], row['longitude']], popup = row['state_code']).add_to(map)\n",
        "\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "112DTMAeM2jm"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxSyWRrIulLU"
      },
      "source": [
        "## try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "dKJUJbXYumyR",
        "outputId": "2542995e-6f45-41b3-d714-eba50a7482dd"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "std_deviation = 2\n",
        "mean = df['avg_participants'].mean()\n",
        "std = df['avg_participants'].std()\n",
        "\n",
        "upper_threshold = mean + (std_deviation * std)\n",
        "lower_threshold = mean - (std_deviation * std)\n",
        "df = df[(df['avg_participants'] >= lower_threshold) & (df['avg_participants'] <= upper_threshold)]\n",
        "len(df)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauDMATBundX"
      },
      "source": [
        "## run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poBveSn0M2jn",
        "outputId": "81464be3-e685-4b7a-9011-ccbfcdc36094"
      },
      "outputs": [],
      "source": [
        "# Add economic indicators\n",
        "df = add_nasdaq_annual_changes(df)\n",
        "indicator_code = 'NY.GDP.MKTP.KD.ZG'\n",
        "df = add_economic_indicators(df, indicator_code)\n",
        "indicator_code = 'SL.UEM.TOTL.ZS'\n",
        "df = add_economic_indicators(df, indicator_code)\n",
        "\n",
        "random_state = 42\n",
        "set_seed(random_state)\n",
        "\n",
        "# Preprocess the data\n",
        "X, y = preprocess_data_classifier(df, useKNNImputer=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxIy2c5nGl7p",
        "outputId": "23fa92f9-1bfc-42b6-a63a-6f52f37e0ee5"
      },
      "outputs": [],
      "source": [
        "print(len(y_train))\n",
        "print(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De7JFlXbu0y1",
        "outputId": "eb2f78c0-0c8d-405f-91c6-6f235e811d31"
      },
      "outputs": [],
      "source": [
        "# Calculate the ratio of negative class to positive class\n",
        "train_ratio = float(y_train.value_counts()[0]) / y_train.value_counts()[1]\n",
        "print(round(train_ratio, 2))\n",
        "test_ratio = float(y_test.value_counts()[0]) / y_test.value_counts()[1]\n",
        "round(test_ratio, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bv9xiWUM2jn"
      },
      "source": [
        "# Train predict and evaluate classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5kyQq4X1X-r"
      },
      "source": [
        "## XG Boost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v2etibIIFmN"
      },
      "source": [
        "### cross-validation with stratified sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_yaL2X4t0krz",
        "outputId": "eb840947-0d95-4063-a6ad-06d195d8994c"
      },
      "outputs": [],
      "source": [
        "fold = 5\n",
        "#np.zeros(fold)\n",
        "for i, (train_index, test_index) in enumerate(cross_validation_generator(X, y, fold)):\n",
        "  print(f\"Fold {i}, ratio {round(get_ratio(y[train_index]), 2)}:\")\n",
        "  xgb_clf = train_xgb_model(X.iloc[train_index] ,  y[train_index])\n",
        "  xgb_pred, xgb_prob = predict_model(xgb_clf, X.iloc[test_index])\n",
        "  evaluate_model(y[test_index], xgb_pred, xgb_prob, threshold=0.5)\n",
        "\n",
        "  plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "  plot_auc_roc_curve(y[test_index], xgb_prob, model_name='XG-Boost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pgy4gc_IMAo"
      },
      "source": [
        "### single split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kQyAVn1rM2jn",
        "outputId": "7e5eef41-68e8-4efa-d69b-b25a35761b1e"
      },
      "outputs": [],
      "source": [
        "xgb_clf = train_xgb_model(X_train, y_train)\n",
        "xgb_pred, xgb_prob = predict_model(xgb_clf, X_test)\n",
        "evaluate_model(y_test, xgb_pred, xgb_prob, threshold=0.5)\n",
        "cv_results_xgb = perform_cross_validation(xgb_clf, X_train, y_train, n_splits=5, random_state=random_state)\n",
        "\n",
        "plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "plot_auc_roc_curve(y_test, xgb_prob, model_name='XG-Boost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRP-zg_K1lbT"
      },
      "source": [
        "## Random Forest Ver2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6HZSWPKTM2jn",
        "outputId": "ad3c8b81-a700-4708-a007-af9e713410e3"
      },
      "outputs": [],
      "source": [
        "rfv2_clf = train_rfv2_model(X_train, y_train)\n",
        "rfv2_pred, rfv2_prob = predict_model(rfv2_clf, X_test)\n",
        "evaluate_model(y_test, rfv2_pred, rfv2_prob)\n",
        "cv_results_rfv2 = perform_cross_validation(rfv2_clf, X_train, y_train, n_splits=5, random_state=random_state)\n",
        "\n",
        "plot_feature_importances(rfv2_clf, feature_names=X.columns, num_of_features=10)\n",
        "plot_auc_roc_curve(y_test, rfv2_prob, model_name='randomForestV2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH3jOszA1qjE"
      },
      "source": [
        "## Fandom Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NjkK8KJuM2jn",
        "outputId": "739fb521-c416-4522-abd8-c7e4a35c2f96"
      },
      "outputs": [],
      "source": [
        "rf_clf = train_rf_model(X_train, y_train)\n",
        "rf_pred, rf_prob = predict_model(rf_clf, X_test)\n",
        "evaluate_model(y_test, rf_pred, rf_prob)\n",
        "cv_results_rf = perform_cross_validation(rf_clf, X_train, y_train, n_splits=5, random_state=random_state)\n",
        "\n",
        "plot_feature_importances(rf_clf, feature_names=X.columns, num_of_features=10)\n",
        "plot_auc_roc_curve(y_test, rf_prob, model_name='randomForest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inl8K6oUF8KO"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iM3W5wk6M2jo",
        "outputId": "bb0ced8c-2a61-4ec2-b485-461b00b0b7c4"
      },
      "outputs": [],
      "source": [
        "svm_clf = train_svm_model(X_train, y_train)\n",
        "svm_pred, svm_prob = predict_model(svm_clf, X_test)\n",
        "evaluate_model(y_test, svm_pred, svm_prob)\n",
        "cv_results_SVM = perform_cross_validation(svm_clf, X_train, y_train, n_splits=5, random_state=random_state)\n",
        "\n",
        "plot_auc_roc_curve(y_test, svm_prob, model_name='SVM')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip7huHQEOMJC"
      },
      "source": [
        "# Ensemble classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL5_z0tRSiCC"
      },
      "source": [
        "## Ensemble with SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-RoSmmmwPrUR",
        "outputId": "a76cde38-8c22-4d1a-a43c-349348cc9600"
      },
      "outputs": [],
      "source": [
        "# Combine predictions using majority voting\n",
        "\n",
        "# Stack the predictions into a matrix\n",
        "predictions = np.vstack((xgb_pred, rfv2_pred, svm_pred)).T\n",
        "\n",
        "# Majority voting\n",
        "ensemble_pred, _ = mode(predictions, axis=1)\n",
        "ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "# Combine probabilities (e.g., by averaging them)\n",
        "ensemble_prob = (xgb_prob + rfv2_prob + svm_prob) / 3\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "evaluate_model(y_test, ensemble_pred, ensemble_prob, threshold=0.5)\n",
        "\n",
        "# Plot feature importances and AUC-ROC curves\n",
        "plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "plot_auc_roc_curve(y_test, ensemble_prob, model_name='Ensemble')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsE1hH08Snco"
      },
      "source": [
        "## Ensemble without SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "61PT5w9xR_Qy",
        "outputId": "a3979def-0122-4b92-e914-947e383ae196"
      },
      "outputs": [],
      "source": [
        "# Combine predictions using majority voting\n",
        "\n",
        "# Stack the predictions into a matrix\n",
        "predictions = np.vstack((xgb_pred, rfv2_pred, rf_pred)).T\n",
        "\n",
        "# Majority voting\n",
        "ensemble_pred, _ = mode(predictions, axis=1)\n",
        "ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "# Combine probabilities (e.g., by averaging them)\n",
        "ensemble_prob = (xgb_prob + rfv2_prob + rf_prob) / 3\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "evaluate_model(y_test, ensemble_pred, ensemble_prob, threshold=0.5)\n",
        "\n",
        "# Plot feature importances and AUC-ROC curves\n",
        "plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "plot_auc_roc_curve(y_test, ensemble_prob, model_name='Ensemble')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXqDFrcqHbp4"
      },
      "source": [
        "## Ensemble all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s_dUWYThHgP5",
        "outputId": "b17ca2c7-1644-4048-8cae-c4238f8da269"
      },
      "outputs": [],
      "source": [
        "# Combine predictions using majority voting\n",
        "\n",
        "# Stack the predictions into a matrix\n",
        "predictions = np.vstack((xgb_pred, rfv2_pred, rf_pred, svm_pred)).T\n",
        "\n",
        "# Majority voting\n",
        "ensemble_pred, _ = mode(predictions, axis=1)\n",
        "ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "# Combine probabilities (e.g., by averaging them)\n",
        "ensemble_prob = (xgb_prob + rfv2_prob + rf_prob + svm_prob) / 4\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "evaluate_model(y_test, ensemble_pred, ensemble_prob, threshold=0.5)\n",
        "\n",
        "# Plot feature importances and AUC-ROC curves\n",
        "plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "plot_auc_roc_curve(y_test, ensemble_prob, model_name='Ensemble')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLJc9ozSQLBo"
      },
      "source": [
        "# Analyse classifier results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKU5VPw0ArLI"
      },
      "source": [
        "## Combine with the original features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "XPPYIxrp1OjP",
        "outputId": "ecdfd600-0d38-47ad-d30e-d6c0ed6b698b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame with all features, y_test, and predictions\n",
        "result_df = pd.DataFrame(X_test, columns=X.columns)\n",
        "result_df['Actual'] = y_test.values\n",
        "'''\n",
        "result_df['Predicted_xgb'] = xgb_pred\n",
        "result_df['Probability_xgb'] = xgb_prob\n",
        "result_df['Predicted_rfv2'] = rfv2_pred\n",
        "result_df['Probability_rfv2'] = rfv2_prob\n",
        "result_df['Predicted_rf'] = rf_pred\n",
        "result_df['Probability_rf'] = rf_prob\n",
        "result_df['Predicted_svm'] = svm_pred\n",
        "result_df['Probability_svm'] = svm_prob\n",
        "'''\n",
        "result_df['Predicted_ensemble'] = ensemble_pred\n",
        "result_df['Probability_ensemble'] = ensemble_prob\n",
        "\n",
        "# Display the DataFrame\n",
        "result_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otOXyBK1OgXD"
      },
      "source": [
        "## try - drafts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFfwTOcqPpa-"
      },
      "outputs": [],
      "source": [
        "df1 = load_data('../data/startup_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUGTRQekICxZ",
        "outputId": "d3bd8816-5121-4f5f-f16a-af0f05bf4e4b"
      },
      "outputs": [],
      "source": [
        "result_df_ok = result_df[result_df['Predicted_ensemble'] == result_df['Actual']]\n",
        "result_df_fail = result_df[result_df['Predicted_ensemble'] != result_df['Actual']]\n",
        "\n",
        "print(result_df_ok['category_code_biotech'].value_counts() / len(result_df_ok))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWVbPO1_ICxZ",
        "outputId": "345a88a4-80a7-4f39-8c6b-8f79a3b5d9d3"
      },
      "outputs": [],
      "source": [
        "# Correlation analysis for incorrect predictions, to see which features correlate with the errors, focusing on predicted values\n",
        "incorrect_corr = abs(result_df_fail.corr())\n",
        "print(\"Correlation in Incorrect Predictions with Predicted Values:\\n\", incorrect_corr['Predicted_ensemble'].sort_values(ascending=False).head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nZGsoQwICxZ"
      },
      "outputs": [],
      "source": [
        "# Add a new column 'predicted_correctly' to the DataFrame\n",
        "result_df['predicted_correctly'] = (result_df['Predicted_ensemble'] == result_df['Actual']).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hZOX3pG7ICxa",
        "outputId": "5add361f-43a9-4cdb-db10-a7881bdc8aee"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the total predictions for each category and the correct prediction rate\n",
        "category_analysis = {}\n",
        "\n",
        "for column in result_df.columns:\n",
        "    if column.startswith('category_code_'):\n",
        "        total = result_df[column].sum()  # total instances of this category\n",
        "        correct = result_df[result_df['predicted_correctly'] == 1][column].sum()\n",
        "        accuracy = correct / total if total > 0 else 0\n",
        "        incorrect = total - correct\n",
        "        category_name = column.replace('category_code_', '')\n",
        "        category_analysis[category_name] = {'Total': total, 'Correct': correct, 'Incorrect': incorrect, 'Accuracy': accuracy}\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "category_df = pd.DataFrame.from_dict(category_analysis, orient='index')\n",
        "category_df = category_df.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count of 0\n",
        "category_df = category_df[category_df['Total'] > 0]\n",
        "\n",
        "print(category_df)\n",
        "\n",
        "# Plot the accuracy with quantitative information\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Accuracy', color=color)\n",
        "ax1.bar(category_df.index, category_df['Accuracy'], color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Create a second y-axis for the total counts\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(category_df.index, category_df['Total'], color=color, marker='o')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Category Analysis: Accuracy vs. Total Predictions')\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp1fxv7UkTWM"
      },
      "source": [
        "## The classifier Performance on different categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "YEwjIwwSICxa",
        "outputId": "a19406d9-6665-4ce0-87c8-3ca02239031c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the total predictions for each category and the correct/incorrect prediction counts\n",
        "category_analysis = {}\n",
        "\n",
        "for column in result_df.columns:\n",
        "    if column.startswith('category_code_'):\n",
        "        total = result_df[column].sum()  # total instances of this category\n",
        "        correct = result_df[result_df['predicted_correctly'] == 1][column].sum()\n",
        "        incorrect = total - correct\n",
        "        category_name = column.replace('category_code_', '')\n",
        "        category_analysis[category_name] = {'Total': total, 'Correct': correct, 'Incorrect': incorrect}\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "category_df = pd.DataFrame.from_dict(category_analysis, orient='index')\n",
        "category_df = category_df.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count <5\n",
        "category_df = category_df[category_df['Total'] > 5]\n",
        "\n",
        "print(category_df)\n",
        "\n",
        "# Plot the correct and incorrect predictions side by side with a secondary y-axis for total predictions\n",
        "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(category_df.index))\n",
        "\n",
        "# Bars for correct predictions\n",
        "bars1 = ax1.bar(index, category_df['Correct'], bar_width, label='Correct Predictions', color='tab:green')\n",
        "\n",
        "# Bars for incorrect predictions\n",
        "bars2 = ax1.bar(index + bar_width, category_df['Incorrect'], bar_width, label='Incorrect Predictions', color='tab:red')\n",
        "\n",
        "# Primary y-axis\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Correct vs. Incorrect Predictions by Category')\n",
        "ax1.set_xticks(index + bar_width / 2)\n",
        "ax1.set_xticklabels(category_df.index, rotation=45, ha='right')\n",
        "ax1.legend(loc='upper left')\n",
        "\n",
        "# Secondary y-axis for total predictions\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(index + bar_width / 2, category_df['Total'], color=color, marker='o', linestyle='--')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_CbDPr2kh6B"
      },
      "source": [
        "### same for 5-fold results aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9shPG8a0ICxa",
        "outputId": "d04497fc-c367-41bb-b351-c2c808ff8491"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Assuming your result_df has the necessary columns to be used as features\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "\n",
        "category_analysis_cv = []\n",
        "\n",
        "for train_index, test_index in kf.split(result_df):\n",
        "    train_df, test_df = result_df.iloc[train_index], result_df.iloc[test_index]\n",
        "\n",
        "    # Ensure only the original feature columns are used\n",
        "    feature_columns = X.columns  # Assuming `X` contains the original feature columns\n",
        "\n",
        "    X_train, y_train = train_df[feature_columns], train_df['Actual']\n",
        "    X_test, y_test = test_df[feature_columns], test_df['Actual']\n",
        "\n",
        "    # Replace this with your actual model fitting and predicting code\n",
        "    xgb_pred, xgb_prob = predict_model(xgb_clf, X_test)\n",
        "    rfv2_pred, rfv2_prob = predict_model(rfv2_clf, X_test)\n",
        "    svm_pred, svm_prob = predict_model(svm_clf, X_test)\n",
        "\n",
        "    # Stack the predictions into a matrix\n",
        "    predictions = np.vstack((xgb_pred, rfv2_pred, svm_pred)).T\n",
        "\n",
        "    # Majority voting\n",
        "    ensemble_pred, _ = mode(predictions, axis=1)\n",
        "    ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "    # Store the predicted and actual values in test_df\n",
        "    test_df['Predicted'] = ensemble_pred\n",
        "\n",
        "    # Now calculate the statistics for this fold\n",
        "    for column in result_df.columns:\n",
        "        if column.startswith('category_code_'):\n",
        "            total = test_df[column].sum()  # total instances of this category in the fold\n",
        "            correct = test_df[(test_df['Predicted'] == test_df['Actual'])][column].sum()\n",
        "            incorrect = total - correct\n",
        "            accuracy = correct / total if total > 0 else 0\n",
        "            category_name = column.replace('category_code_', '')\n",
        "            category_analysis_cv.append({'Category': category_name, 'Total': total, 'Correct': correct, 'Incorrect': incorrect, 'Accuracy': accuracy})\n",
        "\n",
        "# Aggregate results across folds\n",
        "category_df_cv = pd.DataFrame(category_analysis_cv)\n",
        "category_df_cv = category_df_cv.groupby('Category').sum()\n",
        "category_df_cv['Accuracy'] = category_df_cv['Correct'] / category_df_cv['Total']\n",
        "\n",
        "# Sort by the most common categories\n",
        "category_df_cv = category_df_cv.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count of <5\n",
        "category_df_cv = category_df_cv[category_df_cv['Total'] > 5]\n",
        "\n",
        "# Set the width for the bars\n",
        "bar_width = 0.35\n",
        "\n",
        "# Plotting Correct vs Incorrect predictions side by side\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Correct & Incorrect Predictions', color=color)\n",
        "\n",
        "# Set the positions for the bars\n",
        "index = np.arange(len(category_df_cv))\n",
        "\n",
        "# Plot the bars side by side\n",
        "ax1.bar(index - bar_width/2, category_df_cv['Correct'], bar_width, color='tab:green', label='Correct')\n",
        "ax1.bar(index + bar_width/2, category_df_cv['Incorrect'], bar_width, color='tab:red', label='Incorrect')\n",
        "\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.set_xticks(index)\n",
        "ax1.set_xticklabels(category_df_cv.index, rotation=45, ha='right')\n",
        "\n",
        "# Create a second y-axis for the total counts\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:purple'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(index, category_df_cv['Total'], color=color, marker='o', label='Total Predictions')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Category Analysis: Accuracy vs. Total Predictions (5-Fold CV)')\n",
        "fig.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# # Plotting Correct vs Incorrect predictions along with total predictions\n",
        "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# color = 'tab:blue'\n",
        "# ax1.set_xlabel('Category')\n",
        "# ax1.set_ylabel('Correct & Incorrect Predictions', color=color)\n",
        "# ax1.bar(category_df_cv.index, category_df_cv['Correct'], color='tab:green', label='Correct')\n",
        "# ax1.bar(category_df_cv.index, category_df_cv['Incorrect'], color='tab:red', label='Incorrect', bottom=category_df_cv['Correct'])\n",
        "# ax1.tick_params(axis='y', labelcolor=color)\n",
        "# plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# # Create a second y-axis for the total counts\n",
        "# ax2 = ax1.twinx()\n",
        "# color = 'tab:purple'\n",
        "# ax2.set_ylabel('Total Predictions', color=color)\n",
        "# ax2.plot(category_df_cv.index, category_df_cv['Total'], color=color, marker='o', label='Total Predictions')\n",
        "# ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# plt.title('Category Analysis: Accuracy vs. Total Predictions (5-Fold CV)')\n",
        "# fig.tight_layout()\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Kk93Y9avICxb",
        "outputId": "5d5cc338-8ebb-4993-9e41-52fcb5422634"
      },
      "outputs": [],
      "source": [
        "# Extract GDP and UEM columns\n",
        "gdp_columns = [col for col in result_df.columns if 'GDP_growth_at_year' in col]\n",
        "uem_columns = [col for col in result_df.columns if 'UEM_growth_at_year' in col]\n",
        "\n",
        "# Calculate mean prediction correctness for each year\n",
        "gdp_accuracy = result_df.groupby('predicted_correctly')[gdp_columns].mean().T\n",
        "uem_accuracy = result_df.groupby('predicted_correctly')[uem_columns].mean().T\n",
        "\n",
        "# Assign a vector of 0-10 to the 'Year' column\n",
        "gdp_accuracy['Year'] = list(range(11))\n",
        "uem_accuracy['Year'] = list(range(11))\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# GDP Growth plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(gdp_accuracy['Year'], gdp_accuracy[1], label='Correctly Predicted', marker='o')\n",
        "plt.plot(gdp_accuracy['Year'], gdp_accuracy[0], label='Incorrectly Predicted', marker='o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average GDP Growth')\n",
        "plt.title('Model Performance Based on GDP Growth')\n",
        "plt.legend()\n",
        "\n",
        "# UEM Growth plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(uem_accuracy['Year'], uem_accuracy[1], label='Correctly Predicted', marker='o')\n",
        "plt.plot(uem_accuracy['Year'], uem_accuracy[0], label='Incorrectly Predicted', marker='o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average UEM Growth')\n",
        "plt.title('Model Performance Based on UEM Growth')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "WKG53LChNzDt",
        "outputId": "6a5b2232-1bcc-4e51-86a9-68f09710d872"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plot distribution for relationships on the left\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.kdeplot(correct_original_df['relationships'], shade=True, label='Correct', color='g')\n",
        "sns.kdeplot(incorrect_original_df['relationships'], shade=True, label='Incorrect', color='r')\n",
        "plt.title('Distribution of \"relationships\"')\n",
        "plt.legend()\n",
        "\n",
        "# Plot distribution for founded_at_year on the right\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(correct_original_df['founded_at_year'], shade=True, label='Correct', color='g')\n",
        "sns.kdeplot(incorrect_original_df['founded_at_year'], shade=True, label='Incorrect', color='r')\n",
        "plt.title('Distribution of \"founded_at_year\"')\n",
        "plt.legend()\n",
        "\n",
        "# Add a big title to the entire figure\n",
        "plt.suptitle('High effect Feature Distributions for Correct and Incorrect Predictions', fontsize=16, y=1.05)\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jiwwHegfPrQw",
        "outputId": "810184a2-da8c-47ae-ce66-1b4889dce601"
      },
      "outputs": [],
      "source": [
        "df1.category_code.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RzQhnJfE4Dg",
        "outputId": "79562ff9-566e-44fe-cef7-2fbf6796fe10"
      },
      "outputs": [],
      "source": [
        "result_df_ok = result_df[result_df['Predicted_ensemble'] == result_df['Actual']]\n",
        "result_df_fail = result_df[result_df['Predicted_ensemble'] != result_df['Actual']]\n",
        "\n",
        "print(result_df_ok['category_code_biotech'].value_counts() / len(result_df_ok))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTjSMVj5PYsR",
        "outputId": "6e536cb9-f8c2-44ee-98f9-e1ba475b7a42"
      },
      "outputs": [],
      "source": [
        "print(result_df_ok.category_code_biotech.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "Y0Pg4BrgO8FH",
        "outputId": "8d603ce7-346a-4f41-cb1a-5c8eb6063357"
      },
      "outputs": [],
      "source": [
        "result_df_fail.category_code_finance.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Mf7RrVOyvs",
        "outputId": "8535dcd0-5242-4aee-88b5-a0aa93d6405c"
      },
      "outputs": [],
      "source": [
        "result_df_fail['category_code_biotech'] = result_df_fail.category_code_biotech.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['category_code_biotech'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['category_code_biotech'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLdIA7LzN1b2",
        "outputId": "0e9f14c0-61ca-436e-d0de-8115710f4f65"
      },
      "outputs": [],
      "source": [
        "result_df_fail['category_code_software'] = result_df_fail.category_code_software.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['category_code_software'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['category_code_software'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "eYqLPlyiNNie",
        "outputId": "794b9889-d778-4a55-c8ca-725d7f190f40"
      },
      "outputs": [],
      "source": [
        "result_df_fail['is_othercategory'] = result_df_fail.is_othercategory.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['is_othercategory'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['is_othercategory'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "OpJzXL3ULSHy",
        "outputId": "7dd1599d-63e7-4908-d8ce-1a2b8e3ed4cb"
      },
      "outputs": [],
      "source": [
        "result_df.is_othercategory.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnJUoeV-j9D-"
      },
      "source": [
        "# Regressors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIxabMgXLjnJ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate',\n",
        "'category_code', 'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising',\n",
        "'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting', 'is_othercategory',\n",
        "'has_roundB', 'has_roundC', 'has_roundD', 'has_VC', 'has_angel', 'has_roundA',\n",
        "'''\n",
        "'''\n",
        "'closed_at', 'age_first_funding_year', 'age_last_funding_year',\n",
        "'age_first_milestone_year', 'age_last_milestone_year', 'funding_rounds', 'funding_total_usd',\n",
        "'milestones', 'avg_participants',\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl7LR1GiTW01"
      },
      "source": [
        "## predict age_first_funding_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XUTO3jo3Tcid",
        "outputId": "b8664825-5b40-4979-9413-fc1ddab0d7e9"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['age_first_funding_year']\n",
        "df1 = df.drop('age_first_funding_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_first_funding_year', tolerance = 0.4)\n",
        "\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Custom Accuracy within {1} year: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt1vWATvUHkd"
      },
      "source": [
        "## age_last_funding_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b--3jEsgYMir",
        "outputId": "c8948cce-f3fe-4a5d-e444-7885cf7a24dd"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['age_last_funding_year']\n",
        "df1 = df.drop('age_last_funding_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_last_funding_year', tolerance = 0.3)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} year: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q51yGtqzYyPO"
      },
      "source": [
        "## funding_rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MsgWojm6YyXN",
        "outputId": "f9fece6a-4311-4a13-d0d3-8b6951ccd685"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "df1 = df.copy()\n",
        "\n",
        "# Drop rows where 'age_first_milestone_year' is NaN\n",
        "df1.dropna(subset=['age_first_milestone_year'], inplace=True)\n",
        "print(len(df1))\n",
        "y = df1['age_first_milestone_year']\n",
        "df1 = df1.drop('age_first_milestone_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_first_milestone_year', tolerance = 0.3)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} round: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlNgby_-Y6Ae"
      },
      "source": [
        "## funding_total_usd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VKOAlDalY6Jw",
        "outputId": "d43ffb00-757d-40fb-f1fe-d2e0af8de145"
      },
      "outputs": [],
      "source": [
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df, useKNNImputer=True)\n",
        "y = df['funding_total_usd'] # Create target\n",
        "X = X.drop('funding_total_usd', axis=1)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'funding_total_usd', tolerance = 0.4)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} mln usd: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IlMty2qZTVX"
      },
      "source": [
        "## milestones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zy-Nd-ZsZVKS",
        "outputId": "a431c925-ca76-4110-88cc-3b0a6f9246de"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['milestones']\n",
        "df1 = df.copy()\n",
        "df1 = df1.drop('milestones', axis=1)\n",
        "\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'milestones')\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} mln usd: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LaFZz1W0UGTm",
        "outputId": "93a4987b-a41c-4326-d823-a2bf4680aff4"
      },
      "outputs": [],
      "source": [
        "'age_first_funding_year', 'age_last_funding_year',\n",
        "'age_first_milestone_year', 'age_last_milestone_year', 'funding_rounds', 'funding_total_usd',\n",
        "'milestones'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
