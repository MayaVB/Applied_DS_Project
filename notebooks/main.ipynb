{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMn2Zz06M2jh"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLBwNxwn3oog"
      },
      "source": [
        "This notebook presents several classifiers aiming to predict startups success (aquired or failed, no IPO data in the imput dataset) based on the avaliable data.\n",
        " For the input data analysis, please view EDA notebood in the same repository.\n",
        " The dataset can be found here: https://www.kaggle.com/datasets/manishkc06/startup-success-prediction/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivrkwzqf4JDX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-CMo8UO3pro"
      },
      "source": [
        " # Take code from git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mj02UewM8va",
        "outputId": "27b5db75-5758-4088-8513-5845ab49d1ae"
      },
      "outputs": [],
      "source": [
        "# !rm -r Applied_DS_Project # pay attention!\n",
        "# !git clone https://github.com/MayaVB/Applied_DS_Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwFPs4tJQlDU",
        "outputId": "0513a5e4-a5cc-48af-9728-14cb4ea1cd6e"
      },
      "outputs": [],
      "source": [
        "# !ls Applied_DS_Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzB6GBanNbxC"
      },
      "outputs": [],
      "source": [
        "# !ls Applied_DS_Project/src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OUrJNfVQp65"
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkPohH49QqHd",
        "outputId": "15040e68-9b16-41cc-cbbb-2dcb36d9cc69"
      },
      "outputs": [],
      "source": [
        "# !pip install -r Applied_DS_Project/requirements.txt\n",
        "\n",
        "#need to restart again after the installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDhtedT4RV75"
      },
      "outputs": [],
      "source": [
        "# consider for future features\n",
        "# %pip install yfinance\n",
        "# %pip install tweepy\n",
        "# %pip install wbdata pandas\n",
        "# %pip install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or-0hjlUM4An"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgC6z8LXM2jk",
        "outputId": "b687d762-23db-4fbc-8a2e-b9a759031419"
      },
      "outputs": [],
      "source": [
        "# set working directory:\n",
        "# %cd Applied_DS_Project/src\n",
        "\n",
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.stats import mode\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from eval import plot_feature_importances, plot_auc_roc_curve, perform_cross_validation, plot_feature_importances_kfold_agg\n",
        "from getdata import add_nasdaq_annual_changes, add_economic_indicators\n",
        "from models import train_xgb_model, train_rf_model, train_svm_model, train_decision_tree_model\n",
        "from models import cross_validate_model_using_StratifiedKFold, cross_validate_ensemble_using_StratifiedKFold, evaluate_model, predict_model\n",
        "from printstatistics import print_correlations_Spearman_and_Pearson\n",
        "from preprocess import preprocess_data_classifier, preprocess_data\n",
        "from utils import set_seed, load_data\n",
        "from regression_models import train_and_evaluate_r\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj-Ps9XMu33N"
      },
      "source": [
        "# Load data and add economics indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poBveSn0M2jn",
        "outputId": "33497305-7365-46d9-913d-9dce058fcf6f"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "df = load_data('../data/startup_data.csv')\n",
        "\n",
        "# Add economic indicators\n",
        "df = add_nasdaq_annual_changes(df)\n",
        "indicator_code = 'NY.GDP.MKTP.KD.ZG'\n",
        "df = add_economic_indicators(df, indicator_code)\n",
        "indicator_code = 'SL.UEM.TOTL.ZS'\n",
        "df = add_economic_indicators(df, indicator_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfqIpHj_h9cy"
      },
      "source": [
        "# Set seed for reproducability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZIbCH4Lh9ma"
      },
      "outputs": [],
      "source": [
        "random_state = 42\n",
        "set_seed(random_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bv9xiWUM2jn"
      },
      "source": [
        "# Classifiers aquired vs closed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWGBM9duiRw6"
      },
      "source": [
        "## Preprocessing for Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziptvvNmiR_p"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "X, y = preprocess_data_classifier(df, useKNNImputer=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5kyQq4X1X-r"
      },
      "source": [
        "## XG Boost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v2etibIIFmN"
      },
      "source": [
        "### cross-validation with 5-fold stratified sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_0_LeOjHu33V",
        "outputId": "0a42de9f-fbc5-4650-fa18-09aa0a8170d5"
      },
      "outputs": [],
      "source": [
        "# Initialize your XGBoost model\n",
        "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results_xgb = cross_validate_model_using_StratifiedKFold(xgb_clf, X_train, y_train, n_splits=5, random_state=random_state, \n",
        "                                                            print_avg_confusionMatrix=True,\n",
        "                                                            print_target_distribution=True)\n",
        "\n",
        "# Plot feature importances- 5 fold\n",
        "plot_feature_importances_kfold_agg(cv_results_xgb['feature_importances'], X_train.columns.tolist(), n_features=15)\n",
        "\n",
        "# Train the final model on the entire training data\n",
        "xgb_clf = train_xgb_model(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "xgb_pred, xgb_prob = predict_model(xgb_clf, X_test)\n",
        "\n",
        "# Evaluate model on test set\n",
        "metrics['XGBoost'] = evaluate_model(y_test, xgb_pred, xgb_prob, threshold=0.5, \n",
        "                                    print_metrics=True, \n",
        "                                    print_report=True, \n",
        "                                    show_confusion_mat=True)\n",
        "\n",
        "metrics['XGBoost']['Kappa'] = round(cv_results_xgb['mean_kappa'], 2)\n",
        "\n",
        "# Plot feature importances- 1 set\n",
        "plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=15)\n",
        "\n",
        "# Plot AUC-ROC curve\n",
        "plot_auc_roc_curve(y_test, xgb_prob, model_name='XG-Boost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH3jOszA1qjE"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize your XGBoost model\n",
        "rf_clf = RandomForestClassifier()\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results_rf = cross_validate_model_using_StratifiedKFold(rf_clf, X_train, y_train, n_splits=5, random_state=random_state, \n",
        "                                                            print_avg_confusionMatrix=True,\n",
        "                                                            print_target_distribution=True)\n",
        "\n",
        "# Plot feature importances- 5 fold\n",
        "plot_feature_importances_kfold_agg(cv_results_rf['feature_importances'], X_train.columns.tolist(), n_features=15)\n",
        "\n",
        "# Train the final model on the entire training data\n",
        "rf_clf = train_rf_model(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "rf_pred, rf_prob = predict_model(rf_clf, X_test)\n",
        "\n",
        "# Evaluate model on test set\n",
        "metrics['RandomForest'] = evaluate_model(y_test, rf_pred, rf_prob, threshold=0.5, \n",
        "                                    print_metrics=True, \n",
        "                                    print_report=True, \n",
        "                                    show_confusion_mat=True)\n",
        "\n",
        "metrics['RandomForest']['Kappa'] = round(cv_results_rf['mean_kappa'], 2)\n",
        "\n",
        "# Plot feature importances- 1 set\n",
        "plot_feature_importances(rf_clf, feature_names=X.columns, num_of_features=15)\n",
        "\n",
        "# Plot AUC-ROC curve\n",
        "plot_auc_roc_curve(y_test, rf_prob, model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inl8K6oUF8KO"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d7FlRmEBu33Y",
        "outputId": "555774c3-2ab4-419f-b4c9-5f8ec706aa5d"
      },
      "outputs": [],
      "source": [
        "# # Initialize your XGBoost model\n",
        "svm_clf = SVC(probability=True)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results_svm = cross_validate_model_using_StratifiedKFold(svm_clf, X_train, y_train, n_splits=5, random_state=random_state, save_feature_impact_across_folds=False)\n",
        "\n",
        "# Train the final model on the entire training data\n",
        "svm_clf = train_svm_model(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "svm_pred, svm_prob = predict_model(svm_clf, X_test)\n",
        "metrics['SVM'] = evaluate_model(y_test, svm_pred, svm_prob, threshold=0.5)\n",
        "metrics['SVM']['Kappa'] = round(cv_results_svm['mean_kappa'], 2)\n",
        "\n",
        "# Plot AUC-ROC curve\n",
        "plot_auc_roc_curve(y_test, svm_prob, model_name='SVM')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNu6Ck4Iu33Z"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XaK8eh5Mu33Z",
        "outputId": "a86b2693-81cd-44a8-fd85-56e988da624c"
      },
      "outputs": [],
      "source": [
        "# Initialize your XGBoost model\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results_dt = cross_validate_model_using_StratifiedKFold(dt_clf, X_train, y_train, n_splits=5, random_state=random_state, \n",
        "                                                            print_avg_confusionMatrix=True,\n",
        "                                                            print_target_distribution=True)\n",
        "\n",
        "# Train the final model on the entire training data\n",
        "dt_clf = train_decision_tree_model(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "dt_pred, dt_prob = predict_model(dt_clf, X_test)\n",
        "\n",
        "# Evaluate model on test set\n",
        "metrics['DecisionTree'] = evaluate_model(y_test, dt_pred, dt_prob, threshold=0.5, \n",
        "                                    print_metrics=True, \n",
        "                                    print_report=True, \n",
        "                                    show_confusion_mat=True)\n",
        "\n",
        "metrics['DecisionTree']['Kappa'] = round(cv_results_dt['mean_kappa'], 2)\n",
        "\n",
        "# Plot feature importances\n",
        "plot_feature_importances(dt_clf, feature_names=X.columns, num_of_features=10)\n",
        "\n",
        "# Plot AUC-ROC curve\n",
        "plot_auc_roc_curve(y_test, dt_prob, model_name='DecisionTree')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip7huHQEOMJC"
      },
      "source": [
        "## Ensemble classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsE1hH08Snco"
      },
      "source": [
        "### Ensemble selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "models = [xgb_clf, rf_clf]  # List of models\n",
        "ensemble_results = cross_validate_ensemble_using_StratifiedKFold(models, X, y, n_splits=5, random_state=42, print_avg_confusionMatrix=True, print_sum_confusionMatrix=True, print_target_distribution=True)\n",
        "\n",
        "# Extract ensemble metrics\n",
        "predictions = np.vstack((xgb_pred, rf_pred)).T\n",
        "\n",
        "# Majority voting\n",
        "ensemble_pred, _ = mode(predictions, axis=1)\n",
        "ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "# Combine probabilities (e.g., by averaging them)\n",
        "ensemble_prob = (xgb_prob + rf_prob) / 2\n",
        "\n",
        "# Calculate and print metrics for the ensemble\n",
        "metrics['Ensemble2'] = evaluate_model(y_test, ensemble_pred, ensemble_prob, threshold=0.5)\n",
        "\n",
        "# Plot feature importances and AUC-ROC curves\n",
        "plot_feature_importances(xgb_clf, feature_names=X.columns, num_of_features=10)\n",
        "\n",
        "plot_auc_roc_curve(y_test, ensemble_prob, model_name='Ensemble')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLJc9ozSQLBo"
      },
      "source": [
        "## Analyse classifier results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ2fXau6u33q"
      },
      "source": [
        "plot all models results graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "-JQ8QUxvu33q",
        "outputId": "0dbc4a3f-8d51-4d91-86f6-e9a558b9ffc8"
      },
      "outputs": [],
      "source": [
        "# Define the models\n",
        "models = ['XGBoost', 'RandomForest', 'SVM', 'DecisionTree', 'Ensemble']\n",
        "colors = sns.color_palette('coolwarm', n_colors=len(models))\n",
        "\n",
        "# Create a dictionary to map the model names to the pastel colors\n",
        "color_mapping = dict(zip(models, colors))\n",
        "\n",
        "# Convert metrics to DataFrame for plotting\n",
        "metrics_df = pd.DataFrame(metrics).T\n",
        "metrics_df = metrics_df.reset_index().melt(id_vars='index', var_name='Metric', value_name='Score')\n",
        "metrics_df.columns = ['Model', 'Metric', 'Score']\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Use seaborn to create the bar plot with the pastel colors\n",
        "ax = sns.barplot(\n",
        "    x='Metric',\n",
        "    y='Score',\n",
        "    hue='Model',\n",
        "    data=metrics_df,\n",
        "    palette=color_mapping\n",
        ")\n",
        "\n",
        "# Add the numbers on top of the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.2f}',\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center',\n",
        "                xytext=(0, 9),\n",
        "                textcoords='offset points')\n",
        "\n",
        "plt.title('Model Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metric')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKU5VPw0ArLI"
      },
      "source": [
        "### Combine with the original features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "XPPYIxrp1OjP",
        "outputId": "6b3b95e7-eda0-493c-e68e-5e887d85943c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame with all features, y_test, and predictions\n",
        "result_df = pd.DataFrame(X_test, columns=X.columns)\n",
        "result_df['Actual'] = y_test.values\n",
        "'''\n",
        "result_df['Predicted_xgb'] = xgb_pred\n",
        "result_df['Probability_xgb'] = xgb_prob\n",
        "result_df['Predicted_rfv2'] = rfv2_pred\n",
        "result_df['Probability_rfv2'] = rfv2_prob\n",
        "result_df['Predicted_rf'] = rf_pred\n",
        "result_df['Probability_rf'] = rf_prob\n",
        "result_df['Predicted_svm'] = svm_pred\n",
        "result_df['Probability_svm'] = svm_prob\n",
        "'''\n",
        "result_df['Predicted_ensemble'] = ensemble_pred\n",
        "result_df['Probability_ensemble'] = ensemble_prob\n",
        "\n",
        "# Display the DataFrame\n",
        "result_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otOXyBK1OgXD"
      },
      "source": [
        "### try - drafts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFfwTOcqPpa-"
      },
      "outputs": [],
      "source": [
        "df1 = load_data('../data/startup_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUGTRQekICxZ",
        "outputId": "a3dc68f9-baaa-4532-84d7-c58a222ea2d0"
      },
      "outputs": [],
      "source": [
        "result_df_ok = result_df[result_df['Predicted_ensemble'] == result_df['Actual']]\n",
        "result_df_fail = result_df[result_df['Predicted_ensemble'] != result_df['Actual']]\n",
        "\n",
        "print(result_df_ok['category_code_biotech'].value_counts() / len(result_df_ok))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWVbPO1_ICxZ",
        "outputId": "d4e76983-d53d-45b3-a888-78cd36c9a179"
      },
      "outputs": [],
      "source": [
        "# Correlation analysis for incorrect predictions, to see which features correlate with the errors, focusing on predicted values\n",
        "incorrect_corr = (result_df_fail.corr())\n",
        "print(\"Correlation in Incorrect Predictions with Predicted Values:\\n\", incorrect_corr['Predicted_ensemble'].sort_values(ascending=False).head(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nZGsoQwICxZ"
      },
      "outputs": [],
      "source": [
        "# Add a new column 'predicted_correctly' to the DataFrame\n",
        "result_df['predicted_correctly'] = (result_df['Predicted_ensemble'] == result_df['Actual']).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hZOX3pG7ICxa",
        "outputId": "2175afcc-069e-4f8e-9608-5ad53e455a82"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the total predictions for each category and the correct prediction rate\n",
        "category_analysis = {}\n",
        "\n",
        "for column in result_df.columns:\n",
        "    if column.startswith('category_code_'):\n",
        "        total = result_df[column].sum()  # total instances of this category\n",
        "        correct = result_df[result_df['predicted_correctly'] == 1][column].sum()\n",
        "        accuracy = correct / total if total > 0 else 0\n",
        "        incorrect = total - correct\n",
        "        category_name = column.replace('category_code_', '')\n",
        "        category_analysis[category_name] = {'Total': total, 'Correct': correct, 'Incorrect': incorrect, 'Accuracy': accuracy}\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "category_df = pd.DataFrame.from_dict(category_analysis, orient='index')\n",
        "category_df = category_df.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count of 0\n",
        "category_df = category_df[category_df['Total'] > 0]\n",
        "\n",
        "print(category_df)\n",
        "\n",
        "# Plot the accuracy with quantitative information\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Accuracy', color=color)\n",
        "ax1.bar(category_df.index, category_df['Accuracy'], color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Create a second y-axis for the total counts\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(category_df.index, category_df['Total'], color=color, marker='o')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Category Analysis: Accuracy vs. Total Predictions')\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp1fxv7UkTWM"
      },
      "source": [
        "### The classifier Performance on different categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "YEwjIwwSICxa",
        "outputId": "f11818e4-c43e-4f1c-e0db-7b15f436f927"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the total predictions for each category and the correct/incorrect prediction counts\n",
        "category_analysis = {}\n",
        "\n",
        "for column in result_df.columns:\n",
        "    if column.startswith('category_code_'):\n",
        "        total = result_df[column].sum()  # total instances of this category\n",
        "        correct = result_df[result_df['predicted_correctly'] == 1][column].sum()\n",
        "        incorrect = total - correct\n",
        "        category_name = column.replace('category_code_', '')\n",
        "        category_analysis[category_name] = {'Total': total, 'Correct': correct, 'Incorrect': incorrect}\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "category_df = pd.DataFrame.from_dict(category_analysis, orient='index')\n",
        "category_df = category_df.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count <5\n",
        "category_df = category_df[category_df['Total'] > 5]\n",
        "\n",
        "print(category_df)\n",
        "\n",
        "# Plot the correct and incorrect predictions side by side with a secondary y-axis for total predictions\n",
        "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(category_df.index))\n",
        "\n",
        "# Bars for correct predictions\n",
        "bars1 = ax1.bar(index, category_df['Correct'], bar_width, label='Correct Predictions', color='tab:green')\n",
        "\n",
        "# Bars for incorrect predictions\n",
        "bars2 = ax1.bar(index + bar_width, category_df['Incorrect'], bar_width, label='Incorrect Predictions', color='tab:red')\n",
        "\n",
        "# Primary y-axis\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Correct vs. Incorrect Predictions by Category')\n",
        "ax1.set_xticks(index + bar_width / 2)\n",
        "ax1.set_xticklabels(category_df.index, rotation=45, ha='right')\n",
        "ax1.legend(loc='upper left')\n",
        "\n",
        "# Secondary y-axis for total predictions\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(index + bar_width / 2, category_df['Total'], color=color, marker='o', linestyle='--')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_CbDPr2kh6B"
      },
      "source": [
        "#### same for 5-fold results aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9shPG8a0ICxa",
        "outputId": "b2191721-4934-4624-9a72-b89a4f1e1474"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Assuming your result_df has the necessary columns to be used as features\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "\n",
        "category_analysis_cv = []\n",
        "\n",
        "for train_index, test_index in kf.split(result_df):\n",
        "    train_df, test_df = result_df.iloc[train_index], result_df.iloc[test_index]\n",
        "\n",
        "    # Ensure only the original feature columns are used\n",
        "    feature_columns = X.columns\n",
        "\n",
        "    X_train, y_train = train_df[feature_columns], train_df['Actual']\n",
        "    X_test, y_test = test_df[feature_columns], test_df['Actual']\n",
        "\n",
        "    # Replace this with your actual model fitting and predicting code\n",
        "    xgb_pred, xgb_prob = predict_model(xgb_clf, X_test)\n",
        "    rf_pred, rf_prob = predict_model(rf_clf, X_test)\n",
        "    # svm_pred, svm_prob = predict_model(svm_clf, X_test)\n",
        "\n",
        "    # Stack the predictions into a matrix\n",
        "    predictions = np.vstack((xgb_pred, rf_pred)).T\n",
        "\n",
        "    # Majority voting\n",
        "    ensemble_pred, _ = mode(predictions, axis=1)\n",
        "    ensemble_pred = ensemble_pred.ravel()\n",
        "\n",
        "    # Store the predicted and actual values in test_df\n",
        "    test_df['Predicted'] = ensemble_pred\n",
        "\n",
        "    # Now calculate the statistics for this fold\n",
        "    for column in result_df.columns:\n",
        "        if column.startswith('category_code_'):\n",
        "            total = test_df[column].sum()  # total instances of this category in the fold\n",
        "            correct = test_df[(test_df['Predicted'] == test_df['Actual'])][column].sum()\n",
        "            incorrect = total - correct\n",
        "            accuracy = correct / total if total > 0 else 0\n",
        "            category_name = column.replace('category_code_', '')\n",
        "            category_analysis_cv.append({'Category': category_name, 'Total': total, 'Correct': correct, 'Incorrect': incorrect, 'Accuracy': accuracy})\n",
        "\n",
        "# Aggregate results across folds\n",
        "category_df_cv = pd.DataFrame(category_analysis_cv)\n",
        "category_df_cv = category_df_cv.groupby('Category').sum()\n",
        "category_df_cv['Accuracy'] = category_df_cv['Correct'] / category_df_cv['Total']\n",
        "\n",
        "# Sort by the most common categories\n",
        "category_df_cv = category_df_cv.sort_values(by='Total', ascending=False)\n",
        "\n",
        "# Filter out categories with total prediction count of <5\n",
        "category_df_cv = category_df_cv[category_df_cv['Total'] > 5]\n",
        "\n",
        "# Set the width for the bars\n",
        "bar_width = 0.35\n",
        "\n",
        "# Plotting Correct vs Incorrect predictions side by side\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Category')\n",
        "ax1.set_ylabel('Correct & Incorrect Predictions', color=color)\n",
        "\n",
        "# Set the positions for the bars\n",
        "index = np.arange(len(category_df_cv))\n",
        "\n",
        "# Plot the bars side by side\n",
        "ax1.bar(index - bar_width/2, category_df_cv['Correct'], bar_width, color='tab:green', label='Correct')\n",
        "ax1.bar(index + bar_width/2, category_df_cv['Incorrect'], bar_width, color='tab:red', label='Incorrect')\n",
        "\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.set_xticks(index)\n",
        "ax1.set_xticklabels(category_df_cv.index, rotation=45, ha='right')\n",
        "\n",
        "# Create a second y-axis for the total counts\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:purple'\n",
        "ax2.set_ylabel('Total Predictions', color=color)\n",
        "ax2.plot(index, category_df_cv['Total'], color=color, marker='o', label='Total Predictions')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Category Analysis: Accuracy vs. Total Predictions (5-Fold CV)')\n",
        "fig.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Kk93Y9avICxb",
        "outputId": "156343c4-ad86-40ab-bda8-ddde97fbe8f6"
      },
      "outputs": [],
      "source": [
        "# Extract GDP and UEM columns\n",
        "gdp_columns = [col for col in result_df.columns if 'GDP_growth_at_year' in col]\n",
        "uem_columns = [col for col in result_df.columns if 'UEM_growth_at_year' in col]\n",
        "\n",
        "# Calculate mean prediction correctness for each year\n",
        "gdp_accuracy = result_df.groupby('predicted_correctly')[gdp_columns].mean().T\n",
        "uem_accuracy = result_df.groupby('predicted_correctly')[uem_columns].mean().T\n",
        "\n",
        "# Assign a vector of 0-10 to the 'Year' column\n",
        "gdp_accuracy['Year'] = list(range(11))\n",
        "uem_accuracy['Year'] = list(range(11))\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# GDP Growth plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(gdp_accuracy['Year'], gdp_accuracy[1], label='Correctly Predicted', marker='o')\n",
        "plt.plot(gdp_accuracy['Year'], gdp_accuracy[0], label='Incorrectly Predicted', marker='o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average GDP Growth')\n",
        "plt.title('Model Performance Based on GDP Growth')\n",
        "plt.legend()\n",
        "\n",
        "# UEM Growth plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(uem_accuracy['Year'], uem_accuracy[1], label='Correctly Predicted', marker='o')\n",
        "plt.plot(uem_accuracy['Year'], uem_accuracy[0], label='Incorrectly Predicted', marker='o')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average UEM Growth')\n",
        "plt.title('Model Performance Based on UEM Growth')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKG53LChNzDt"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# plt.figure(figsize=(14, 5))\n",
        "\n",
        "# # Plot distribution for relationships on the left\n",
        "# plt.subplot(1, 2, 1)\n",
        "# sns.kdeplot(correct_original_df['relationships'], shade=True, label='Correct', color='g')\n",
        "# sns.kdeplot(incorrect_original_df['relationships'], shade=True, label='Incorrect', color='r')\n",
        "# plt.title('Distribution of \"relationships\"')\n",
        "# plt.legend()\n",
        "\n",
        "# # Plot distribution for founded_at_year on the right\n",
        "# plt.subplot(1, 2, 2)\n",
        "# sns.kdeplot(correct_original_df['founded_at_year'], shade=True, label='Correct', color='g')\n",
        "# sns.kdeplot(incorrect_original_df['founded_at_year'], shade=True, label='Incorrect', color='r')\n",
        "# plt.title('Distribution of \"founded_at_year\"')\n",
        "# plt.legend()\n",
        "\n",
        "# # Add a big title to the entire figure\n",
        "# plt.suptitle('High effect Feature Distributions for Correct and Incorrect Predictions', fontsize=16, y=1.05)\n",
        "\n",
        "# # Adjust layout for better spacing\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jiwwHegfPrQw",
        "outputId": "37a13398-de71-42d6-d550-d28f037f3f23"
      },
      "outputs": [],
      "source": [
        "df1.category_code.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Mf7RrVOyvs",
        "outputId": "f0f3b388-ae25-4589-eb99-a9019134755e"
      },
      "outputs": [],
      "source": [
        "result_df_fail['category_code_biotech'] = result_df_fail.category_code_biotech.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['category_code_biotech'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['category_code_biotech'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLdIA7LzN1b2",
        "outputId": "ed347e9d-f87a-4f07-c064-30171d340943"
      },
      "outputs": [],
      "source": [
        "result_df_fail['category_code_software'] = result_df_fail.category_code_software.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['category_code_software'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['category_code_software'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYqLPlyiNNie",
        "outputId": "0e5e6aed-2fd2-4130-e837-3d6b1bab49f2"
      },
      "outputs": [],
      "source": [
        "result_df_fail['category_code_other'] = result_df_fail.category_code_other.apply(lambda x: 1 if x > 0.6 else 0)\n",
        "#print(result_df_fail['is_othercategory'].value_counts() / len(result_df_fail))\n",
        "print(result_df_fail['category_code_other'].value_counts() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSFcJUPwu330",
        "outputId": "8fd0f8aa-d95b-4c4c-aeec-7335f214f878"
      },
      "outputs": [],
      "source": [
        "# # Create label\n",
        "df['status_code'] = df['status'].map({'acquired': 1, 'closed': 0})\n",
        "print_correlations_Spearman_and_Pearson(df['GDP_growth_at_year_0'], df['status_code'])\n",
        "print_correlations_Spearman_and_Pearson(df['relationships'], df['status_code'])\n",
        "print_correlations_Spearman_and_Pearson(df['avg_participants'], df['status_code'])\n",
        "print_correlations_Spearman_and_Pearson(df['has_roundC'], df['status_code'])\n",
        "print_correlations_Spearman_and_Pearson(df['has_roundD'], df['status_code'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "OpJzXL3ULSHy",
        "outputId": "11991265-bade-4542-891a-fff8d1695a0a"
      },
      "outputs": [],
      "source": [
        "result_df.category_code_other.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnJUoeV-j9D-"
      },
      "source": [
        "# Regressors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zIxabMgXLjnJ",
        "outputId": "cc8dc015-e5e8-4e9d-a1c8-7d908ff14eed"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate',\n",
        "'category_code', 'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising',\n",
        "'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting', 'is_othercategory',\n",
        "'has_roundB', 'has_roundC', 'has_roundD', 'has_VC', 'has_angel', 'has_roundA',\n",
        "'''\n",
        "'''\n",
        "'closed_at', 'age_first_funding_year', 'age_last_funding_year',\n",
        "'age_first_milestone_year', 'age_last_milestone_year', 'funding_rounds', 'funding_total_usd',\n",
        "'milestones', 'avg_participants',\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl7LR1GiTW01"
      },
      "source": [
        "## predict age_first_funding_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SIEa80t4jVID",
        "outputId": "7845ff05-50cc-4d59-d0c4-e3071836e97d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create target\n",
        "y = df['age_first_funding_year']\n",
        "df1 = df.drop('age_first_funding_year', axis=1)\n",
        "\n",
        "# Preprocess the data\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "\n",
        "# Define the cross-validation strategy (k-fold with 5 splits)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "\n",
        "# Initialize the XGBoost regressor\n",
        "xgb_regressor = xgb.XGBRegressor(random_state=random_state)\n",
        "\n",
        "# Perform cross-validation and get the predictions on the test set\n",
        "y_pred_cv = cross_val_predict(xgb_regressor, X, y, cv=kf)\n",
        "\n",
        "# Calculate mean squared error for cross-validated predictions\n",
        "mse_cv = mean_squared_error(y, y_pred_cv)\n",
        "print(f\"Cross-Validated MSE: {mse_cv:.4f}\")\n",
        "\n",
        "# Custom accuracy for cross-validation\n",
        "accuracy_abs_cv = (abs((y_pred_cv - y) / y) <= 1).mean()\n",
        "print(f\"Custom Accuracy within 1 year (Cross-Validation): {accuracy_abs_cv * 100:.2f}%\")\n",
        "\n",
        "# Now train and evaluate the model normally\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_first_funding_year', tolerance=0.4)\n",
        "\n",
        "# Custom accuracy on the test set\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Custom Accuracy within 1 year (Test Set): {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XUTO3jo3Tcid",
        "outputId": "e435e9e7-58a4-4a85-b02d-393682cdb7b3"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['age_first_funding_year']\n",
        "df1 = df.drop('age_first_funding_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_first_funding_year', tolerance = 0.4)\n",
        "\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Custom Accuracy within {1} year: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt1vWATvUHkd"
      },
      "source": [
        "## age_last_funding_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b--3jEsgYMir",
        "outputId": "776c257c-7d1e-4f09-b7ee-a444f61ed1a2"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['age_last_funding_year']\n",
        "df1 = df.drop('age_last_funding_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_last_funding_year', tolerance = 0.3)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} year: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q51yGtqzYyPO"
      },
      "source": [
        "## funding_rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MsgWojm6YyXN",
        "outputId": "e04ee6d5-5b3c-40f2-ed5e-863b767a4629"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "df1 = df.copy()\n",
        "\n",
        "# Drop rows where 'age_first_milestone_year' is NaN\n",
        "df1.dropna(subset=['age_first_milestone_year'], inplace=True)\n",
        "print(len(df1))\n",
        "y = df1['age_first_milestone_year']\n",
        "df1 = df1.drop('age_first_milestone_year', axis=1)\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'age_first_milestone_year', tolerance = 0.3)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} round: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlNgby_-Y6Ae"
      },
      "source": [
        "## funding_total_usd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VKOAlDalY6Jw",
        "outputId": "f387c6fe-0baa-445f-de34-b9374c2e8588"
      },
      "outputs": [],
      "source": [
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df, useKNNImputer=True)\n",
        "y = df['funding_total_usd'] # Create target\n",
        "X = X.drop('funding_total_usd', axis=1)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'funding_total_usd', tolerance = 0.4)\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} mln usd: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IlMty2qZTVX"
      },
      "source": [
        "## milestones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zy-Nd-ZsZVKS",
        "outputId": "289584c5-95b5-4d26-902f-3d4125280589"
      },
      "outputs": [],
      "source": [
        "# Create target\n",
        "y = df['milestones']\n",
        "df1 = df.copy()\n",
        "df1 = df1.drop('milestones', axis=1)\n",
        "\n",
        "# Preprocess and split the data train and evaluate:\n",
        "X = preprocess_data(df1, useKNNImputer=True)\n",
        "xgb_regressor, X_test, y_test, y_pred = train_and_evaluate_r(X, y, random_state, 'milestones')\n",
        "accuracy_abs = (abs((y_pred - y_test) / y_test) <= 1).mean()\n",
        "print(f\"Accuracy within {1} mln usd: {accuracy_abs * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LaFZz1W0UGTm",
        "outputId": "a55f4db0-901c-4810-ef99-559f3366403d"
      },
      "outputs": [],
      "source": [
        "'age_first_funding_year', 'age_last_funding_year',\n",
        "'age_first_milestone_year', 'age_last_milestone_year', 'funding_rounds', 'funding_total_usd',\n",
        "'milestones'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
