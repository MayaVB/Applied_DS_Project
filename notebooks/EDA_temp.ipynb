{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Startup Sucess EDA -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StartUp Sucess- EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from tabulate import tabulate\n",
    "# !pip install folium\n",
    "import folium\n",
    "# %pip install yfinance\n",
    "# %pip install tweepy\n",
    "# %pip install wbdata pandas\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "# import tweepy\n",
    "import wbdata\n",
    "from preprocess import preprocess_data_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and adjust data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add economic info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add & adjust data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data:\n",
    "df = pd.read_csv('../data/startup_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['relationships'])\n",
    "plt.title('Relationships Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['funding_total_usd'])\n",
    "plt.title('funding_total_usd Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned, xx = preprocess_data_classifier(df, useKNNImputer=False, remove_feature_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_cleaned['relationships'])\n",
    "plt.title('Relationships Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_cleaned['relationships'])\n",
    "plt.title('Relationships cleaned distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Create lable\n",
    "df['status_code'] = df['status'].map({'acquired': 1, 'closed': 0})\n",
    "\n",
    "# Convert the date column to datetime\n",
    "df['founded_at_date'] = pd.to_datetime(df['founded_at'])\n",
    "\n",
    "# Extract year, month, and day into separate columns\n",
    "df['founded_at_year'] = df['founded_at_date'].dt.year\n",
    "df['founded_at_month'] = df['founded_at_date'].dt.month\n",
    "df['founded_at_day'] = df['founded_at_date'].dt.day\n",
    "\n",
    "# remove irrelevant columns:\n",
    "df = df.drop(columns=['status', 'founded_at', 'name', 'id', 'state_code.1', 'object_id', 'category_code', 'labels', 'closed_at',\"Unnamed: 6\",\"Unnamed: 0\"])\n",
    "# Add nasdaq data\n",
    "df = add_nasdaq_annual_changes(df)\n",
    "\n",
    "indicator_code = 'NY.GDP.MKTP.KD.ZG'\n",
    "df = add_economic_indicators(df, indicator_code) # will replace add_us_gdp_growth_data_over_years\n",
    "\n",
    "indicator_code = 'SL.UEM.TOTL.ZS'  # Unemployment rate, percentage of total labor force\n",
    "df = add_economic_indicators(df, indicator_code) # will replace add_us_gdp_growth_data_over_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "print(columns_with_nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 columns with missing values - 'age_first_milestone_year', 'age_last_milestone_year'. The companies that have no value in those columns also have 0 in milestones column. So, in order to deal with the missing values, we used a correlation matrix and we discovered that age_last_funding_year column has the highest correlation with 'age_first_milestone_year' & 'age_last_milestone_year'. (It make sense since one the company's milestones coulld be raising certain amount of money which could be done by funding).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the columns with the missing values:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "sns.histplot(df['age_first_milestone_year'], bins=20, color='blue',ax=axes[0])\n",
    "axes[0].set_title('age_first_milestone_year', fontsize=15)\n",
    "axes[0].set_xlabel('age_first_milestone_year', fontsize=14)\n",
    "axes[0].set_ylabel('Count', fontsize=14)\n",
    "axes[0].tick_params(axis='x', labelsize=12)\n",
    "axes[0].tick_params(axis='y', labelsize=12)\n",
    "plt.grid()\n",
    "print('age_first_milestone_year', ' skewness:', df['age_first_milestone_year'].skew(axis = 0, skipna = True) )\n",
    "df['age_first_milestone_year'].describe(include='all')\n",
    "\n",
    "sns.histplot(data=df['age_last_milestone_year'],bins=20, color='red',ax=axes[1])\n",
    "axes[1].set_title('age_last_milestone_year', fontsize=15)\n",
    "axes[1].set_xlabel('age_last_milestone_year', fontsize=14)\n",
    "axes[1].set_ylabel('Count', fontsize=14)\n",
    "axes[1].tick_params(axis='x', labelsize=12)\n",
    "axes[1].tick_params(axis='y', labelsize=12)\n",
    "plt.grid()\n",
    "print('age_last_milestone_year', ' skewness:', df['age_last_milestone_year'].skew(axis = 0, skipna = True) )\n",
    "\n",
    "\n",
    "# Get descriptive statistics\n",
    "desc_first = df['age_first_milestone_year'].describe(include='all')\n",
    "desc_last = df['age_last_milestone_year'].describe(include='all')\n",
    "\n",
    "# Combine the statistics into a single DataFrame\n",
    "desc_table = pd.DataFrame({\n",
    "    'age_first_milestone_year': desc_first,\n",
    "    'age_last_milestone_year': desc_last\n",
    "})\n",
    "\n",
    "# Display the table with tabulate\n",
    "print(tabulate(desc_table, headers='keys', tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look for correlations for those columns.\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df.corr(numeric_only = True)\n",
    "\n",
    "# Find correlations with the columns containing missing values\n",
    "correlations_first_milestone_age = correlation_matrix['age_first_milestone_year'].abs().sort_values(ascending=False)\n",
    "correlations_age_last_milestone_year = correlation_matrix['age_last_milestone_year'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Print the correlations\n",
    "print(correlations_first_milestone_age[correlations_first_milestone_age>0.5])\n",
    "print(correlations_age_last_milestone_year[correlations_age_last_milestone_year>0.5])\n",
    "\n",
    "# We see that last_funding_age is highly correlated with our columns.\n",
    "# It could make sense since it's reasonable that one of a company's milestones is to raise certin amount of money which could\n",
    "# be done by funding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fill in the missing values we used the basic knn algorithm. Then, we evaluated the effectiveness of the imputation process and assessed the quality of the imputed data by comparing summary statistics (e.g., mean, median, standard deviation) before and after the imputation. We see that the results are very much alike, so we can proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# fill in the missing values using knn:\n",
    "\n",
    "# Create a copy of the DataFrame with only the columns of interest \n",
    "columns_with_missing_values = ['age_first_milestone_year','age_last_milestone_year']\n",
    "columns_of_interest = ['age_last_funding_year'] + columns_with_missing_values\n",
    "data_subset = df[columns_of_interest].copy()\n",
    "\n",
    "# Instantiate the KNNImputer with the desired number of neighbors\n",
    "knn_imputer = KNNImputer(n_neighbors=5) \n",
    "\n",
    "# Fit and transform the data\n",
    "imputed_data = knn_imputer.fit_transform(data_subset)\n",
    "\n",
    "# Replace the missing values in the original DataFrame with the imputed values\n",
    "for i, col in enumerate(columns_with_missing_values):\n",
    "    df[col] = imputed_data[:, i + 1]  \n",
    "\n",
    "##### To evaluate the effectiveness of the imputation process and assess the quality of the imputed data, \n",
    "##### we are comparing summary statistics(e.g., mean, median, standard deviation) before (2 cells above) and after the\n",
    "##### imputation (the next cell). We see that the results are very much alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the columns with the missing values:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "sns.histplot(df['age_first_milestone_year'], bins=20, color='blue',ax=axes[0])\n",
    "axes[0].set_title('age_first_milestone_year', fontsize=15)\n",
    "axes[0].set_xlabel('age_first_milestone_year', fontsize=14)\n",
    "axes[0].set_ylabel('Count', fontsize=14)\n",
    "axes[0].tick_params(axis='x', labelsize=12)\n",
    "axes[0].tick_params(axis='y', labelsize=12)\n",
    "plt.grid()\n",
    "print('age_first_milestone_year', ' skewness:', df['age_first_milestone_year'].skew(axis = 0, skipna = True) )\n",
    "df['age_first_milestone_year'].describe(include='all')\n",
    "\n",
    "sns.histplot(data=df['age_last_milestone_year'],bins=20, color='red',ax=axes[1])\n",
    "axes[1].set_title('age_last_milestone_year', fontsize=15)\n",
    "axes[1].set_xlabel('age_last_milestone_year', fontsize=14)\n",
    "axes[1].set_ylabel('Count', fontsize=14)\n",
    "axes[1].tick_params(axis='x', labelsize=12)\n",
    "axes[1].tick_params(axis='y', labelsize=12)\n",
    "plt.grid()\n",
    "print('age_last_milestone_year', ' skewness:', df['age_last_milestone_year'].skew(axis = 0, skipna = True) )\n",
    "\n",
    "\n",
    "# Get descriptive statistics\n",
    "desc_first = df['age_first_milestone_year'].describe(include='all')\n",
    "desc_last = df['age_last_milestone_year'].describe(include='all')\n",
    "\n",
    "# Combine the statistics into a single DataFrame\n",
    "desc_table = pd.DataFrame({\n",
    "    'age_first_milestone_year': desc_first,\n",
    "    'age_last_milestone_year': desc_last\n",
    "})\n",
    "\n",
    "# Display the table with tabulate\n",
    "print(tabulate(desc_table, headers='keys', tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #deal with different date formats\n",
    "# from datetime import datetime\n",
    "\n",
    "# dates_in_df = ['last_funding_at','first_funding_at','founded_at']\n",
    "\n",
    "# formatted_dates = []\n",
    "# formatted_dates_MONTH_DAY = []\n",
    "# formatted_dates_YEAR = []\n",
    "# for ind in dates_in_df:\n",
    "#     dates = df[ind]\n",
    "#     for date in dates:\n",
    "#         # Try to parse the date string as MM/DD/YYYY\n",
    "#         try:\n",
    "#             parsed_date = datetime.strptime(date, '%m/%d/%Y')\n",
    "#         # If it fails, assume the date string is in M/D/YYYY format\n",
    "#         except ValueError:\n",
    "#             parsed_date = datetime.strptime(date, '%m/%d/%Y')\n",
    "#         # Extract month and year from the parsed date\n",
    "#         day = parsed_date.strftime('%d')\n",
    "#         month = parsed_date.strftime('%m')\n",
    "#         year = parsed_date.strftime('%Y')\n",
    "#         # Combine month and year as a string in MM/YYYY format\n",
    "#         formatted_date_MONTH_DAY = f\"{month}/{day}\"\n",
    "#         formatted_dates_MONTH_DAY.append(formatted_date_MONTH_DAY)\n",
    "#         # year format only\n",
    "#         formatted_date_YEAR = f\"{year}\"\n",
    "#         formatted_dates_YEAR.append(formatted_date_YEAR)\n",
    "#         # Convert the parsed date back to a string in MM/DD/YYYY format\n",
    "#         formatted_date = parsed_date.strftime('%m/%d/%Y')\n",
    "#         formatted_dates.append(formatted_date)\n",
    "               \n",
    "     \n",
    "#     df[ind] = formatted_dates\n",
    "#     df[ind + 'MONTH/DAY'] = formatted_dates_MONTH_DAY\n",
    "#     df[ind + 'YEAR'] = formatted_dates_YEAR\n",
    "#     formatted_dates = []\n",
    "#     formatted_dates_MONTH_DAY = []\n",
    "#     formatted_dates_YEAR = []\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_counts = df['category_code'].value_counts()\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.barplot(x=category_counts.values, y=category_counts.index, palette='Set2')\n",
    "# plt.title('Most Common Categories', fontsize=16)\n",
    "# plt.xlabel('Count', fontsize=14)\n",
    "# plt.ylabel('Category', fontsize=14)\n",
    "# plt.xticks(rotation=0, fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to nominal and numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_col = df.describe().columns # to get the numeric column\n",
    "numeric_data = df[numeric_col]\n",
    "nominal_data = df.drop(numeric_col, axis=1)\n",
    "numeric_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Created a folium map – a geographic interface – where we can see all the companies around the world, and we color coded it so that the successful companies are green colored, and the unsuccessful companies are red colored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map centered on the first location in the dataframe\n",
    "map = folium.Map(location=[numeric_data['latitude'][0], numeric_data['longitude'][0]], zoom_start=5)\n",
    "\n",
    "for i in range(len(numeric_data)):\n",
    "    popup_text = f\"{df['status_code'][i]} \"\n",
    "    if df['status_code'][i] == 1:\n",
    "        c = 'green'\n",
    "    else:# Target = closed\n",
    "        c = 'red'\n",
    "\n",
    "    folium.Marker([numeric_data['latitude'][i], numeric_data['longitude'][i]],\n",
    "        icon=folium.Icon(color=c,popup = popup_text), icon_size=(70, 70)).add_to(map)\n",
    "    \n",
    "# Display the map\n",
    "map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used cross-tabulation (crosstab) table to show that most of the companies are in CA and 2/3 of them were successful. So, it might be an indication that there's a strong connection between the companies location and their chance to succeed. We then show a similar connection using in_Top500 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-tabulation (crosstab) table\n",
    "ct = pd.crosstab(index=df['status_code'], columns=[df['is_NY'],df['is_MA'], df['is_CA'], df['is_TX'],df['is_otherstate']])\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-tabulation (crosstab) table\n",
    "ct = pd.crosstab(index=df['status_code'], columns=[df['is_top500']])\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed, using boxplot, that in funding_total_usd column we have outliers. We found that there was one company that raised a lot of money, compared to the other companies. We decided to use log data transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=\"funding_total_usd\", data=numeric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers:\n",
    "data_mean = df['funding_total_usd'].mean()\n",
    "data_std = df['funding_total_usd'].std()\n",
    "cut_off = data_std * 3\n",
    "lower_bound = data_mean - cut_off\n",
    "upper_bound = data_mean + cut_off\n",
    "df.loc[(df['funding_total_usd'] > upper_bound) | (df['funding_total_usd'] < lower_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df['funding_total_usd_log'] = np.log(df['funding_total_usd'])\n",
    "scaler = MinMaxScaler()\n",
    "df['total_funding_normalized'] = scaler.fit_transform(df[['funding_total_usd_log']])\n",
    "\n",
    "\n",
    "# df[['funding_total_usd','total_funding_normalized']].head()\n",
    "sns.displot(df['total_funding_normalized'], bins=25, color='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=\"total_funding_normalized\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # after preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot funding bins using a bar plot\n",
    "bin_edges = [0, 100000, 500000, 1000000, 5000000, 10000000, df['funding_total_usd'].max()] # binning funding_total_usd- i use this since histplot was unclear\n",
    "bin_labels = ['0-100K', '100K-500K', '500K-1M', '1M-5M', '5M-10M', '10M+']\n",
    "df['funding_bins'] = pd.cut(df['funding_total_usd'], bins=bin_edges, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "funding_bin_counts = df['funding_bins'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=funding_bin_counts.index, y=funding_bin_counts.values, palette='viridis')\n",
    "plt.title('Distribution of Funding Total USD Bins')\n",
    "plt.xlabel('Funding Bins')\n",
    "plt.ylabel('Number of Startups')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['relationships'])\n",
    "plt.title('Relationships Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot\n",
    "sns.pairplot(df[['age_first_funding_year', 'age_last_funding_year', 'relationships', 'funding_rounds', 'funding_total_usd', 'milestones']])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of status\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.countplot(x='status_code', data=df, palette='viridis')\n",
    "plt.title('Distribution of Startup Status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot for funding rounds distribution by status\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='status_code', y='funding_rounds', data=df, palette='viridis')\n",
    "plt.title('Funding Rounds Distribution by Status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('df.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
